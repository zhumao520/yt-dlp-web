# -*- coding: utf-8 -*-
"""
ä¸‹è½½ç®¡ç†å™¨ V2 - æ¨¡å—åŒ–é‡æ„ç‰ˆ

ä½¿ç”¨æ¨¡å—åŒ–æ¶æ„ï¼Œæé«˜ä»£ç å¯ç»´æŠ¤æ€§å’Œå¯æ‰©å±•æ€§
"""

import os
import uuid
import logging
import threading
import hashlib
import time
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional, List
from concurrent.futures import ThreadPoolExecutor
from urllib.parse import urlparse, unquote

# é¢„å¯¼å…¥å¸¸ç”¨æ¨¡å—ï¼Œé¿å…é‡å¤å¯¼å…¥
try:
    import yt_dlp
    YT_DLP_AVAILABLE = True
except ImportError:
    YT_DLP_AVAILABLE = False
    yt_dlp = None

try:
    import requests
    REQUESTS_AVAILABLE = True
except ImportError:
    REQUESTS_AVAILABLE = False
    requests = None

# å¯¼å…¥æ¨¡å—åŒ–ç»„ä»¶
from .retry_manager import RetryManager
from .ffmpeg_tools import FFmpegTools
from .filename_processor import FilenameProcessor
from .youtube_strategies import YouTubeStrategies
from .video_extractor import VideoExtractor

logger = logging.getLogger(__name__)


def safe_execute(default_return=None, log_error=True):
    """ç»Ÿä¸€çš„é”™è¯¯å¤„ç†è£…é¥°å™¨ï¼Œå‡å°‘é‡å¤çš„try-exceptä»£ç """
    def decorator(func):
        def wrapper(*args, **kwargs):
            try:
                return func(*args, **kwargs)
            except Exception as e:
                if log_error:
                    logger.error(f"âŒ {func.__name__} æ‰§è¡Œå¤±è´¥: {e}")
                return default_return
        return wrapper
    return decorator


class URLUtils:
    """URLå¤„ç†å·¥å…·ç±»ï¼Œé¿å…é‡å¤çš„URLæ“ä½œé€»è¾‘"""

    @staticmethod
    def extract_filename_from_url(url: str) -> Optional[str]:
        """ä»URLä¸­æå–çœŸå®çš„æ–‡ä»¶å"""
        # å°è¯•ä»URLå‚æ•°ä¸­æå–æ–‡ä»¶å
        if 'file=' in url:
            # æå–fileå‚æ•°
            match = re.search(r'file=([^&]+)', url)
            if match:
                file_param = unquote(match.group(1))
                # æå–æ–‡ä»¶åéƒ¨åˆ†
                filename = file_param.split('/')[-1]
                if filename and '.' in filename:
                    logger.info(f"ğŸ” ä»URLå‚æ•°æå–æ–‡ä»¶å: {filename}")
                    return filename
        return None

    @staticmethod
    def generate_url_hash(url: str) -> str:
        """ç”ŸæˆURLå“ˆå¸Œï¼Œç”¨äºç»­ä¼ åŠŸèƒ½"""
        try:
            # æ ‡å‡†åŒ–URLï¼ˆç§»é™¤æŸ¥è¯¢å‚æ•°ä¸­çš„æ—¶é—´æˆ³ç­‰ï¼‰
            from urllib.parse import parse_qs, urlencode, urlunparse
            parsed = urlparse(url)

            # å¯¹äºæŸäº›å¹³å°ï¼Œç§»é™¤æ—¶é—´æˆ³å‚æ•°
            if parsed.query:
                query_params = parse_qs(parsed.query)
                # ç§»é™¤å¸¸è§çš„æ—¶é—´æˆ³å‚æ•°
                timestamp_params = ['t', 'timestamp', '_t', 'time', 'ts']
                for param in timestamp_params:
                    query_params.pop(param, None)

                # é‡å»ºæŸ¥è¯¢å­—ç¬¦ä¸²
                clean_query = urlencode(query_params, doseq=True)
                parsed = parsed._replace(query=clean_query)

            clean_url = urlunparse(parsed)
            return hashlib.md5(clean_url.encode('utf-8')).hexdigest()[:12]
        except Exception as e:
            logger.warning(f"âš ï¸ ç”ŸæˆURLå“ˆå¸Œå¤±è´¥ï¼Œä½¿ç”¨åŸURL: {e}")
            return hashlib.md5(url.encode('utf-8')).hexdigest()[:12]

    @staticmethod
    def should_fix_extension(url: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦ä¿®å¤æ‰©å±•å"""
        # æ£€æŸ¥URLæ˜¯å¦åŒ…å«å¯èƒ½å¯¼è‡´æ‰©å±•åé—®é¢˜çš„æ¨¡å¼
        problematic_patterns = [
            'remote_control.php',
            '.php?',
            'file=%2F',  # URLç¼–ç çš„æ–‡ä»¶è·¯å¾„
        ]

        for pattern in problematic_patterns:
            if pattern in url:
                # è¿›ä¸€æ­¥æ£€æŸ¥æ˜¯å¦å®é™…æŒ‡å‘è§†é¢‘æ–‡ä»¶
                if any(video_ext in url for video_ext in ['.mp4', '.avi', '.mkv', '.mov', '.flv']):
                    logger.info(f"ğŸ”§ æ£€æµ‹åˆ°éœ€è¦ä¿®å¤æ‰©å±•åçš„URL: {pattern}")
                    return True

        return False


# å¸¸é‡å®šä¹‰
class DownloadConstants:
    """ä¸‹è½½ç›¸å…³å¸¸é‡"""

    # YouTube åŸŸååˆ—è¡¨
    YOUTUBE_DOMAINS = [
        'youtube.com',
        'youtu.be',
        'www.youtube.com',
        'm.youtube.com',
        'music.youtube.com',
        'youtube-nocookie.com'
    ]

    # è¿›åº¦æ—¥å¿—é—´éš”ï¼ˆç™¾åˆ†æ¯”ï¼‰
    PROGRESS_LOG_INTERVAL = 10

    # é»˜è®¤é‡è¯•æ¬¡æ•°
    DEFAULT_RETRIES = 5
    DEFAULT_FRAGMENT_RETRIES = 10


class ConfigManager:
    """ç»Ÿä¸€çš„é…ç½®ç®¡ç†å™¨ï¼Œç¼“å­˜é…ç½®å‡½æ•°é¿å…é‡å¤å¯¼å…¥"""

    _config_func = None
    _database_func = None
    _proxy_helper = None

    @classmethod
    def get_config_func(cls):
        """è·å–é…ç½®å‡½æ•°ï¼ˆç¼“å­˜ï¼‰"""
        if cls._config_func is None:
            def fallback_get_config(key, default=None):
                return os.getenv(key.upper().replace('.', '_'), default)

            try:
                from core.config import get_config
                cls._config_func = get_config
            except ImportError:
                try:
                    from app.core.config import get_config
                    cls._config_func = get_config
                except ImportError:
                    cls._config_func = fallback_get_config
                    logger.warning("âš ï¸ ä½¿ç”¨ç¯å¢ƒå˜é‡ä½œä¸ºé…ç½®æº")

        return cls._config_func

    @classmethod
    def get_database_func(cls):
        """è·å–æ•°æ®åº“å‡½æ•°ï¼ˆç¼“å­˜ï¼‰"""
        if cls._database_func is None:
            try:
                from core.database import get_database
                cls._database_func = get_database
            except ImportError:
                try:
                    from app.core.database import get_database
                    cls._database_func = get_database
                except ImportError:
                    logger.warning("âš ï¸ æ— æ³•å¯¼å…¥æ•°æ®åº“æ¨¡å—")
                    cls._database_func = None

        return cls._database_func

    @classmethod
    def get_proxy_config(cls) -> Optional[str]:
        """è·å–ä»£ç†é…ç½®ï¼ˆç¼“å­˜ï¼‰"""
        if cls._proxy_helper is None:
            try:
                from core.proxy_converter import ProxyHelper
                cls._proxy_helper = ProxyHelper
            except ImportError:
                logger.warning("âš ï¸ æ— æ³•å¯¼å…¥ä»£ç†åŠ©æ‰‹")
                return None

        return cls._proxy_helper.get_ytdlp_proxy("DownloadManager") if cls._proxy_helper else None


class DownloadManagerV2:
    """ä¸‹è½½ç®¡ç†å™¨ V2 - æ¨¡å—åŒ–ç‰ˆæœ¬"""
    
    def __init__(self):
        self.downloads: Dict[str, Dict[str, Any]] = {}
        self.lock = threading.RLock()
        self.executor = None

        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            'total_downloads': 0,
            'successful_downloads': 0,
            'failed_downloads': 0,
            'cancelled_downloads': 0,
            'total_bytes_downloaded': 0,
            'start_time': datetime.now()
        }

        # åˆå§‹åŒ–æ¨¡å—åŒ–ç»„ä»¶
        self._initialize_components()
        self._initialize()
    
    def _initialize_components(self):
        """åˆå§‹åŒ–æ¨¡å—åŒ–ç»„ä»¶"""
        try:
            self.retry_manager = RetryManager()
            self.ffmpeg_tools = FFmpegTools()
            self.filename_processor = FilenameProcessor()
            self.youtube_strategies = YouTubeStrategies()
            self.video_extractor = VideoExtractor()
            
            logger.info("âœ… æ¨¡å—åŒ–ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å—åŒ–ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _get_config_with_log(self, get_config_func, key: str, default, config_type: str = "ä¸‹è½½ç®¡ç†å™¨"):
        """è·å–é…ç½®å¹¶è®°å½•æ¥æº"""
        try:
            # æ£€æŸ¥æ•°æ®åº“è®¾ç½®
            from core.database import get_database
            db = get_database()
            db_value = db.get_setting(key)
            if db_value is not None:
                logger.info(f"ğŸ”§ {config_type}é…ç½®: {key} = {db_value} (æ¥æº: æ•°æ®åº“)")
                return db_value

            # æ£€æŸ¥é…ç½®æ–‡ä»¶
            config_value = get_config_func(key, None)
            if config_value is not None and config_value != default:
                logger.info(f"ğŸ”§ {config_type}é…ç½®: {key} = {config_value} (æ¥æº: é…ç½®æ–‡ä»¶)")
                return config_value

            # ä½¿ç”¨é»˜è®¤å€¼
            logger.info(f"ğŸ”§ {config_type}é…ç½®: {key} = {default} (æ¥æº: é»˜è®¤å€¼)")
            return default

        except Exception as e:
            logger.warning(f"âš ï¸ {config_type}é…ç½®è·å–å¤±è´¥ {key}: {e}")
            return get_config_func(key, default)

    def _initialize(self):
        """åˆå§‹åŒ–ä¸‹è½½ç®¡ç†å™¨"""
        try:
            # ä½¿ç”¨ç»Ÿä¸€çš„é…ç½®ç®¡ç†å™¨
            get_config = ConfigManager.get_config_func()

            # è·å–å¹¶éªŒè¯é…ç½®ï¼ˆå¸¦æ—¥å¿—è®°å½•ï¼‰
            max_concurrent_raw = self._get_config_with_log(get_config, 'downloader.max_concurrent', 3)
            output_dir_raw = self._get_config_with_log(get_config, 'downloader.output_dir', '/app/downloads')
            temp_dir_raw = self._get_config_with_log(get_config, 'downloader.temp_dir', '/app/temp')

            self.max_concurrent = self._validate_config_int(max_concurrent_raw, 'max_concurrent', 1, 10)
            self.output_dir = self._validate_config_path(output_dir_raw, 'output_dir')
            self.temp_dir = self._validate_config_path(temp_dir_raw, 'temp_dir')

            # åˆ›å»ºç›®å½•
            self.output_dir.mkdir(parents=True, exist_ok=True)
            self.temp_dir.mkdir(parents=True, exist_ok=True)

            # æ¸…ç†é—ç•™ä»»åŠ¡
            self._cleanup_orphaned_downloads()

            # åˆ›å»ºçº¿ç¨‹æ± 
            self.executor = ThreadPoolExecutor(max_workers=self.max_concurrent)

            # å¯åŠ¨è‡ªåŠ¨æ¸…ç†
            self._start_cleanup()

            logger.info(f"âœ… ä¸‹è½½ç®¡ç†å™¨V2åˆå§‹åŒ–å®Œæˆ - æœ€å¤§å¹¶å‘: {self.max_concurrent}")
            logger.info(f"ğŸ”§ FFmpegçŠ¶æ€: {'å¯ç”¨' if self.ffmpeg_tools.is_available() else 'ä¸å¯ç”¨'}")
            logger.info(f"ğŸ“‹ å¯ç”¨æå–å™¨: {len(self.video_extractor.get_available_extractors())} ä¸ª")
            logger.info(f"ğŸ¯ YouTubeç­–ç•¥: {len(self.youtube_strategies.get_strategy_list())} ä¸ª")

        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½ç®¡ç†å™¨V2åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _cleanup_orphaned_downloads(self):
        """æ¸…ç†é—ç•™çš„ä¸‹è½½ä»»åŠ¡"""
        try:
            # ä½¿ç”¨ç»Ÿä¸€çš„é…ç½®ç®¡ç†å™¨
            get_database = ConfigManager.get_database_func()
            if not get_database:
                logger.warning("âš ï¸ æ— æ³•å¯¼å…¥æ•°æ®åº“æ¨¡å—ï¼Œè·³è¿‡æ¸…ç†é—ç•™ä»»åŠ¡")
                return

            db = get_database()
            orphaned_downloads = db.execute_query('''
                SELECT id, url FROM downloads
                WHERE status IN ('pending', 'downloading')
            ''')

            if orphaned_downloads:
                logger.info(f"ğŸ§¹ å‘ç° {len(orphaned_downloads)} ä¸ªé—ç•™ä¸‹è½½ä»»åŠ¡ï¼Œæ­£åœ¨æ¸…ç†...")
                
                for download in orphaned_downloads:
                    db.execute_update('''
                        UPDATE downloads
                        SET status = 'failed',
                            error_message = 'åº”ç”¨é‡å¯ï¼Œä»»åŠ¡å·²å–æ¶ˆ',
                            completed_at = CURRENT_TIMESTAMP
                        WHERE id = ?
                    ''', (download['id'],))
                
                logger.info(f"âœ… å·²æ¸…ç† {len(orphaned_downloads)} ä¸ªé—ç•™ä¸‹è½½ä»»åŠ¡")

        except Exception as e:
            logger.error(f"âŒ æ¸…ç†é—ç•™ä¸‹è½½ä»»åŠ¡å¤±è´¥: {e}")
    
    def _start_cleanup(self):
        """å¯åŠ¨è‡ªåŠ¨æ¸…ç†"""
        try:
            from .cleanup import get_cleanup_manager
            cleanup_manager = get_cleanup_manager()
            cleanup_manager.start()
        except Exception as e:
            logger.warning(f"âš ï¸ å¯åŠ¨è‡ªåŠ¨æ¸…ç†å¤±è´¥: {e}")
    
    def create_download(self, url: str, options: Dict[str, Any] = None) -> str:
        """åˆ›å»ºä¸‹è½½ä»»åŠ¡"""
        try:
            download_id = str(uuid.uuid4())

            # æ£€æŸ¥æ˜¯å¦æœ‰ç›¸åŒURLçš„æœªå®Œæˆä¸‹è½½ï¼Œæ”¯æŒç»­ä¼ 
            existing_download = self._find_resumable_download(url)
            if existing_download:
                if existing_download.get('resumable'):
                    # æœ‰éƒ¨åˆ†æ–‡ä»¶ï¼Œåˆ›å»ºæ–°ä»»åŠ¡ä½†ä½¿ç”¨ç»­ä¼ 
                    logger.info(f"ğŸ”„ å‘ç°éƒ¨åˆ†ä¸‹è½½æ–‡ä»¶ï¼Œå°†ç»­ä¼ : {url}")
                elif existing_download.get('from_database'):
                    # æ•°æ®åº“ä¸­çš„å¤±è´¥ä»»åŠ¡ï¼Œå¤ç”¨ID
                    reused_id = existing_download['id']
                    logger.info(f"ğŸ”„ å¤ç”¨æ•°æ®åº“ä¸­çš„å¤±è´¥ä»»åŠ¡: {reused_id}")

                    # é‡æ–°åˆ›å»ºå†…å­˜ä¸­çš„ä¸‹è½½è®°å½•
                    initial_title = None
                    if options and options.get('custom_filename'):
                        initial_title = options['custom_filename']

                    download_info = {
                        'id': reused_id,
                        'url': url,
                        'status': 'pending',
                        'progress': 0,
                        'title': initial_title,
                        'file_path': None,
                        'file_size': None,
                        'error_message': None,
                        'created_at': datetime.now(),
                        'completed_at': None,
                        'options': options or {},
                        'url_hash': URLUtils.generate_url_hash(url)
                    }

                    with self.lock:
                        self.downloads[reused_id] = download_info

                    # ğŸ”§ é‡è¦ï¼šæ¸…ç†é‡è¯•æ•°æ®ï¼Œé‡æ–°å¼€å§‹é‡è¯•è®¡æ•°
                    logger.info(f"ğŸ§¹ æ¸…ç†æ•°æ®åº“å¤ç”¨ä»»åŠ¡çš„é‡è¯•æ•°æ®: {reused_id}")
                    self.retry_manager.clear_retry_data(reused_id)

                    # ğŸ”§ é‡è¦ï¼šé‡æ–°æäº¤æ‰§è¡Œä»»åŠ¡
                    logger.info(f"ğŸš€ é‡æ–°æäº¤æ•°æ®åº“å¤±è´¥ä»»åŠ¡æ‰§è¡Œ: {reused_id}")
                    self.executor.submit(self._execute_download, reused_id)

                    return reused_id
                else:
                    # å†…å­˜ä¸­çš„å¤±è´¥ä»»åŠ¡ï¼Œä¸å¤ç”¨ï¼Œåˆ›å»ºæ–°ä»»åŠ¡
                    logger.info(f"ğŸ†• å†…å­˜ä¸­å­˜åœ¨å¤±è´¥ä»»åŠ¡ï¼Œä½†åˆ›å»ºæ–°ä»»åŠ¡: {existing_download['id']}")
                    # ç»§ç»­æ‰§è¡Œåé¢çš„æ–°ä»»åŠ¡åˆ›å»ºé€»è¾‘

            # åˆ›å»ºä¸‹è½½è®°å½•
            # å¦‚æœæœ‰è‡ªå®šä¹‰æ–‡ä»¶åï¼Œä¼˜å…ˆä½¿ç”¨ä½œä¸ºæ˜¾ç¤ºæ ‡é¢˜
            initial_title = None
            if options and options.get('custom_filename'):
                initial_title = options['custom_filename']
                logger.info(f"ğŸ¯ ä½¿ç”¨è‡ªå®šä¹‰æ–‡ä»¶åä½œä¸ºåˆå§‹æ ‡é¢˜: {initial_title}")

            download_info = {
                'id': download_id,
                'url': url,
                'status': 'pending',
                'progress': 0,
                'title': initial_title,
                'file_path': None,
                'file_size': None,
                'error_message': None,
                'created_at': datetime.now(),
                'completed_at': None,
                'options': options or {},
                'url_hash': URLUtils.generate_url_hash(url)  # æ·»åŠ URLå“ˆå¸Œç”¨äºç»­ä¼ 
            }

            with self.lock:
                self.downloads[download_id] = download_info

            # ä¿å­˜åˆ°æ•°æ®åº“
            self._save_to_database(download_id, url)

            # æ›´æ–°ç»Ÿè®¡
            self._update_stats('download_started')

            # å‘é€äº‹ä»¶
            self._emit_event('DOWNLOAD_STARTED', {
                'download_id': download_id,
                'url': url,
                'title': initial_title,
                'options': options
            })

            # æäº¤ä¸‹è½½ä»»åŠ¡
            self.executor.submit(self._execute_download, download_id)

            logger.info(f"ğŸ“¥ åˆ›å»ºä¸‹è½½ä»»åŠ¡: {download_id} - {url}")
            return download_id

        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºä¸‹è½½ä»»åŠ¡å¤±è´¥: {e}")
            raise



    def _find_resumable_download(self, url: str) -> Optional[Dict[str, Any]]:
        """æŸ¥æ‰¾å¯ç»­ä¼ çš„ä¸‹è½½ä»»åŠ¡"""
        try:
            url_hash = URLUtils.generate_url_hash(url)

            # 1. æ£€æŸ¥æ˜¯å¦æœ‰éƒ¨åˆ†ä¸‹è½½çš„æ–‡ä»¶
            url_hash_files = self._find_partial_files(url_hash)
            if url_hash_files:
                logger.info(f"ğŸ” æ‰¾åˆ°éƒ¨åˆ†ä¸‹è½½æ–‡ä»¶: {[f.name for f in url_hash_files]}")
                # åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿçš„ä¸‹è½½ä¿¡æ¯ç”¨äºç»­ä¼ 
                return {
                    'url': url,
                    'url_hash': url_hash,
                    'partial_files': url_hash_files,
                    'resumable': True
                }

            # 2. æ£€æŸ¥æ•°æ®åº“ä¸­çš„å¤±è´¥ä»»åŠ¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            try:
                get_database = ConfigManager.get_database_func()
                if get_database:
                    db = get_database()
                    cursor = db.execute(
                        "SELECT id, url, status FROM downloads WHERE url = ? AND status IN ('failed', 'cancelled') ORDER BY created_at DESC LIMIT 1",
                        (url,)
                    )
                    row = cursor.fetchone()
                    if row:
                        logger.info(f"ğŸ” æ‰¾åˆ°æ•°æ®åº“ä¸­çš„å¯ç»­ä¼ ä»»åŠ¡: {row[0]}")
                        return {
                            'id': row[0],
                            'url': row[1],
                            'status': row[2],
                            'from_database': True
                        }
            except Exception as e:
                logger.debug(f"æ•°æ®åº“æŸ¥è¯¢å¤±è´¥: {e}")

            return None

        except Exception as e:
            logger.error(f"âŒ æŸ¥æ‰¾ç»­ä¼ ä»»åŠ¡å¤±è´¥: {e}")
            return None

    def add_download(self, url: str, options: Dict[str, Any] = None) -> str:
        """æ·»åŠ ä¸‹è½½ä»»åŠ¡ï¼ˆå‘åå…¼å®¹åˆ«åï¼‰"""
        return self.create_download(url, options)
    
    def get_download(self, download_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ä¸‹è½½ä¿¡æ¯"""
        with self.lock:
            return self.downloads.get(download_id)

    def get_download_status(self, download_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ä¸‹è½½çŠ¶æ€ï¼ˆå‘åå…¼å®¹åˆ«åï¼‰"""
        return self.get_download(download_id)
    
    def get_all_downloads(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰ä¸‹è½½ï¼ˆåŒ…æ‹¬å†…å­˜ä¸­çš„å’Œæ•°æ®åº“ä¸­çš„å†å²è®°å½•ï¼‰"""
        try:
            # è·å–å†…å­˜ä¸­çš„ä¸‹è½½è®°å½•
            with self.lock:
                memory_downloads = list(self.downloads.values())

            # è·å–æ•°æ®åº“ä¸­çš„å†å²è®°å½•
            database_downloads = self._load_from_database()

            # åˆå¹¶è®°å½•ï¼Œé¿å…é‡å¤
            all_downloads = {}

            # å…ˆæ·»åŠ æ•°æ®åº“è®°å½•
            for download in database_downloads:
                all_downloads[download['id']] = download

            # å†æ·»åŠ å†…å­˜è®°å½•ï¼ˆä¼šè¦†ç›–æ•°æ®åº“ä¸­çš„åŒIDè®°å½•ï¼Œç¡®ä¿æœ€æ–°çŠ¶æ€ï¼‰
            for download in memory_downloads:
                all_downloads[download['id']] = download

            # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æŒ‰åˆ›å»ºæ—¶é—´æ’åº
            result = list(all_downloads.values())

            # å®‰å…¨çš„æ’åºå‡½æ•°ï¼Œå¤„ç†datetimeå’Œå­—ç¬¦ä¸²æ··åˆçš„æƒ…å†µ
            def safe_sort_key(download):
                created_at = download.get('created_at')
                if not created_at:
                    return ''

                # å¦‚æœæ˜¯datetimeå¯¹è±¡ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                if hasattr(created_at, 'isoformat'):
                    return created_at.isoformat()

                # å¦‚æœå·²ç»æ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥è¿”å›
                return str(created_at)

            result.sort(key=safe_sort_key, reverse=True)

            logger.debug(f"ğŸ“‹ è¿”å›ä¸‹è½½è®°å½•: å†…å­˜ {len(memory_downloads)} æ¡, æ•°æ®åº“ {len(database_downloads)} æ¡, åˆå¹¶å {len(result)} æ¡")
            return result

        except Exception as e:
            logger.error(f"âŒ è·å–æ‰€æœ‰ä¸‹è½½è®°å½•å¤±è´¥: {e}")
            # å¦‚æœå‡ºé”™ï¼Œè‡³å°‘è¿”å›å†…å­˜ä¸­çš„è®°å½•
            with self.lock:
                return list(self.downloads.values())
    
    def cancel_download(self, download_id: str) -> bool:
        """å–æ¶ˆä¸‹è½½"""
        try:
            with self.lock:
                download_info = self.downloads.get(download_id)
                if not download_info:
                    return False
                
                if download_info['status'] in ['completed', 'failed', 'cancelled']:
                    return False
                
                download_info['status'] = 'cancelled'
                download_info['error_message'] = 'ç”¨æˆ·å–æ¶ˆ'
            
            # æ›´æ–°æ•°æ®åº“
            self._update_database_status(download_id, 'cancelled', error_message='ç”¨æˆ·å–æ¶ˆ')
            
            # æ¸…ç†é‡è¯•æ•°æ®
            self.retry_manager.clear_retry_data(download_id)
            
            logger.info(f"ğŸš« å–æ¶ˆä¸‹è½½: {download_id}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ å–æ¶ˆä¸‹è½½å¤±è´¥: {e}")
            return False

    def _load_from_database(self) -> List[Dict[str, Any]]:
        """ä»æ•°æ®åº“åŠ è½½å†å²ä¸‹è½½è®°å½•"""
        try:
            get_database = ConfigManager.get_database_func()
            if not get_database:
                logger.debug("æ•°æ®åº“æ¨¡å—ä¸å¯ç”¨ï¼Œè¿”å›ç©ºåˆ—è¡¨")
                return []

            db = get_database()

            # è·å–æ•°æ®åº“ä¸­çš„ä¸‹è½½è®°å½•
            records = db.get_download_records(limit=100)  # é™åˆ¶è¿”å›æœ€è¿‘100æ¡è®°å½•

            downloads = []
            for record in records:
                # è½¬æ¢æ•°æ®åº“è®°å½•ä¸ºä¸‹è½½ç®¡ç†å™¨æ ¼å¼
                download_info = {
                    'id': record['id'],
                    'url': record['url'],
                    'title': record['title'],
                    'status': record['status'],
                    'progress': record['progress'] or 0,
                    'file_path': record['file_path'],
                    'file_size': record['file_size'],
                    'error_message': record['error_message'],
                    'created_at': record['created_at'],
                    'completed_at': record['completed_at'],
                    'options': {}  # æ•°æ®åº“ä¸­æ²¡æœ‰å­˜å‚¨options
                }
                downloads.append(download_info)

            logger.debug(f"ğŸ“‹ ä»æ•°æ®åº“åŠ è½½äº† {len(downloads)} æ¡å†å²è®°å½•")
            return downloads

        except Exception as e:
            logger.warning(f"âš ï¸ ä»æ•°æ®åº“åŠ è½½å†å²è®°å½•å¤±è´¥: {e}")
            return []

    def _execute_download(self, download_id: str):
        """æ‰§è¡Œä¸‹è½½ä»»åŠ¡"""
        try:
            with self.lock:
                download_info = self.downloads.get(download_id)
                if not download_info:
                    return

                url = download_info['url']
                options = download_info['options']

            logger.info(f"ğŸ”„ å¼€å§‹æ‰§è¡Œä¸‹è½½: {download_id} - {url}")

            # ğŸ”§ é‡ç½®è¿›åº¦è®°å½•ï¼Œé˜²æ­¢ä¸Šæ¬¡ä¸‹è½½çš„è¿›åº¦å½±å“
            from core.file_utils import ProgressUtils
            ProgressUtils.reset_progress(download_id)

            # æ£€æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
            if self._is_cancelled(download_id):
                logger.info(f"ğŸš« ä¸‹è½½å·²è¢«å–æ¶ˆ: {download_id}")
                return

            # æ›´æ–°çŠ¶æ€ä¸ºä¸‹è½½ä¸­
            self._update_download_status(download_id, 'downloading', 0)

            # æå–è§†é¢‘ä¿¡æ¯
            video_info = self.video_extractor.extract_info(url, options)

            # å†æ¬¡æ£€æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
            if self._is_cancelled(download_id):
                logger.info(f"ğŸš« ä¸‹è½½å·²è¢«å–æ¶ˆï¼ˆæå–ä¿¡æ¯åï¼‰: {download_id}")
                return

            if not video_info or video_info.get('error'):
                error_msg = video_info.get('message', 'æ— æ³•è·å–è§†é¢‘ä¿¡æ¯') if video_info else 'æ— æ³•è·å–è§†é¢‘ä¿¡æ¯'
                self._handle_download_failure(download_id, error_msg)
                return

            # æ›´æ–°æ ‡é¢˜ - ä¼˜å…ˆä¿ç•™è‡ªå®šä¹‰æ–‡ä»¶å
            title = video_info.get('title', 'Unknown')
            with self.lock:
                current_title = self.downloads[download_id].get('title')
                # å¦‚æœå·²ç»æœ‰è‡ªå®šä¹‰æ ‡é¢˜ï¼ˆæ¥è‡ªè‡ªå®šä¹‰æ–‡ä»¶åï¼‰ï¼Œä¸è¦è¦†ç›–å®ƒ
                if not current_title:
                    self.downloads[download_id]['title'] = title
                    logger.info(f"ğŸ“ è®¾ç½®è§†é¢‘æ ‡é¢˜: {title}")
                else:
                    logger.info(f"ğŸ“ ä¿ç•™è‡ªå®šä¹‰æ ‡é¢˜: {current_title} (åŸå§‹æ ‡é¢˜: {title})")
                    title = current_title  # ä½¿ç”¨è‡ªå®šä¹‰æ ‡é¢˜ä½œä¸ºåç»­å¤„ç†çš„æ ‡é¢˜

            # æ£€æµ‹å¹¶è®°å½•æ–‡ä»¶å¤§å°ä¿¡æ¯ï¼ˆä»…æä¾›ä¿¡æ¯ï¼Œä¸é™åˆ¶ä¸‹è½½ï¼‰
            self._detect_and_log_file_size(video_info, title)

            # æœ€åä¸€æ¬¡æ£€æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
            if self._is_cancelled(download_id):
                logger.info(f"ğŸš« ä¸‹è½½å·²è¢«å–æ¶ˆï¼ˆå¼€å§‹ä¸‹è½½å‰ï¼‰: {download_id}")
                return

            # æ‰§è¡Œä¸‹è½½
            file_path = self._download_video(download_id, url, video_info, options)

            if file_path and Path(file_path).exists():
                # ğŸ”§ ä¿®å¤ï¼šæ£€æŸ¥æ˜¯å¦æ˜¯YouTubeå¹³å°ï¼Œé¿å…é‡å¤éŸ³é¢‘è½¬æ¢
                is_youtube = 'youtube.com' in url or 'youtu.be' in url

                if is_youtube:
                    # YouTubeç­–ç•¥å·²ç»å¤„ç†äº†éŸ³é¢‘è½¬æ¢ï¼Œä¸‹è½½ç®¡ç†å™¨ä¸éœ€è¦é‡å¤å¤„ç†
                    logger.info(f"âœ… YouTubeæ–‡ä»¶å·²ç»æ˜¯ç›®æ ‡æ ¼å¼ {Path(file_path).suffix.upper().lstrip('.')}ï¼Œæ— éœ€è½¬æ¢: {Path(file_path).name}")
                else:
                    # å…¶ä»–å¹³å°éœ€è¦ä¸‹è½½ç®¡ç†å™¨çš„éŸ³é¢‘è½¬æ¢é€»è¾‘
                    if self._needs_audio_conversion(options):
                        converted_path = self._convert_to_audio(file_path, options)
                        if converted_path:
                            # åˆ é™¤åŸå§‹æ–‡ä»¶
                            try:
                                Path(file_path).unlink()
                            except:
                                pass
                            file_path = converted_path

                # åº”ç”¨æ™ºèƒ½æ–‡ä»¶å
                if options.get('smart_filename', True):
                    final_path = self._apply_smart_filename(file_path, video_info, options)
                    if final_path:
                        file_path = final_path
                        logger.info(f"âœ… æ™ºèƒ½æ–‡ä»¶ååº”ç”¨æˆåŠŸ: {Path(file_path).name}")

                        # æ›´æ–°æ˜¾ç¤ºæ ‡é¢˜ä¸ºè‡ªå®šä¹‰æ–‡ä»¶åï¼ˆå¦‚æœä½¿ç”¨äº†è‡ªå®šä¹‰æ–‡ä»¶åï¼‰
                        if options.get('custom_filename'):
                            display_title = options['custom_filename']
                            with self.lock:
                                if download_id in self.downloads:
                                    self.downloads[download_id]['title'] = display_title
                            logger.info(f"âœ… æ›´æ–°æ˜¾ç¤ºæ ‡é¢˜ä¸ºè‡ªå®šä¹‰æ–‡ä»¶å: {display_title}")

                            # å‘é€æ ‡é¢˜æ›´æ–°äº‹ä»¶ç»™å‰ç«¯
                            self._emit_event('DOWNLOAD_TITLE_UPDATED', {
                                'download_id': download_id,
                                'title': display_title
                            })
                    else:
                        # å¦‚æœæ™ºèƒ½é‡å‘½åå¤±è´¥ï¼Œè®°å½•è­¦å‘Šä½†ç»§ç»­ä½¿ç”¨å½“å‰è·¯å¾„
                        logger.warning(f"âš ï¸ æ™ºèƒ½æ–‡ä»¶ååº”ç”¨å¤±è´¥ï¼Œä¿æŒåŸæ–‡ä»¶å: {Path(file_path).name}")

                # ç¡®ä¿æ–‡ä»¶å­˜åœ¨å¹¶è·å–æœ€ç»ˆä¿¡æ¯ï¼ˆå»¶è¿Ÿæ£€æŸ¥ä»¥é¿å…æ–‡ä»¶ç³»ç»Ÿå»¶è¿Ÿï¼‰
                final_file_path = Path(file_path)

                # ç®€åŒ–çš„å»¶è¿Ÿæ£€æŸ¥æœºåˆ¶ï¼šç»™æ–‡ä»¶ç³»ç»Ÿä¸€äº›æ—¶é—´å®Œæˆæ“ä½œ
                max_check_attempts = 3  # å‡å°‘åˆ°3æ¬¡
                check_delay = 0.5  # å›ºå®š0.5ç§’å»¶è¿Ÿ

                for attempt in range(max_check_attempts):
                    # æ¯æ¬¡æ£€æŸ¥å‰éƒ½å…ˆç­‰å¾…ï¼Œç»™é‡å‘½åæ“ä½œæ—¶é—´å®Œæˆ
                    if attempt == 0:
                        logger.info(f"ğŸ” ç­‰å¾…{check_delay}ç§’åå¼€å§‹æ–‡ä»¶æ£€æŸ¥...")
                    else:
                        logger.info(f"ğŸ” æ–‡ä»¶æ£€æŸ¥ç¬¬{attempt}æ¬¡æœªæ‰¾åˆ°ï¼Œç­‰å¾…{check_delay}ç§’åé‡è¯•...")

                    time.sleep(check_delay)

                    if final_file_path.exists():
                        if attempt == 0:
                            logger.info(f"âœ… æ–‡ä»¶æ£€æŸ¥æˆåŠŸ")
                        else:
                            logger.info(f"âœ… æ–‡ä»¶æ£€æŸ¥æˆåŠŸï¼Œç¬¬{attempt + 1}æ¬¡å°è¯•åæ‰¾åˆ°æ–‡ä»¶")
                        break

                    # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•å¤±è´¥
                    if attempt == max_check_attempts - 1:
                        # æœ€åä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œè®°å½•è¯¦ç»†ä¿¡æ¯
                        logger.error(f"âŒ æœ€ç»ˆæ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                        logger.error(f"âŒ æ£€æŸ¥è·¯å¾„: {final_file_path.absolute()}")
                        logger.error(f"âŒ çˆ¶ç›®å½•å­˜åœ¨: {final_file_path.parent.exists()}")
                        if final_file_path.parent.exists():
                            logger.error(f"âŒ çˆ¶ç›®å½•å†…å®¹: {list(final_file_path.parent.glob('*'))}")
                        self._handle_download_failure(download_id, 'æœ€ç»ˆæ–‡ä»¶ä¸å­˜åœ¨')
                        return

                file_size = final_file_path.stat().st_size
                logger.info(f"ğŸ“ æœ€ç»ˆæ–‡ä»¶: {final_file_path.name} ({file_size / (1024*1024):.1f}MB)")

                # ä¸‹è½½å’Œåå¤„ç†å®Œå…¨å®Œæˆï¼Œå‘é€å®Œæˆäº‹ä»¶
                self._update_download_status(download_id, 'completed', 100,
                                           file_path=str(final_file_path), file_size=file_size)

                # æ¸…ç†é‡è¯•æ•°æ®
                self.retry_manager.clear_retry_data(download_id)

                logger.info(f"âœ… ä¸‹è½½å®Œæˆ: {download_id} - {title}")
            else:
                self._handle_download_failure(download_id, 'ä¸‹è½½æ–‡ä»¶ä¸å­˜åœ¨')

        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½æ‰§è¡Œå¤±è´¥ {download_id}: {e}")
            self._handle_download_failure(download_id, str(e))

    def _is_cancelled(self, download_id: str) -> bool:
        """æ£€æŸ¥ä¸‹è½½æ˜¯å¦å·²è¢«å–æ¶ˆ"""
        try:
            with self.lock:
                download_info = self.downloads.get(download_id)
                if not download_info:
                    return True  # å¦‚æœè®°å½•ä¸å­˜åœ¨ï¼Œè§†ä¸ºå·²å–æ¶ˆ
                return download_info.get('status') == 'cancelled'
        except Exception as e:
            logger.error(f"âŒ æ£€æŸ¥å–æ¶ˆçŠ¶æ€å¤±è´¥: {e}")
            return False

    def _detect_and_log_file_size(self, video_info: Dict[str, Any], title: str):
        """æ£€æµ‹å¹¶è®°å½•æ–‡ä»¶å¤§å°ä¿¡æ¯ï¼ˆä»…æä¾›ä¿¡æ¯ï¼Œä¸é™åˆ¶ä¸‹è½½ï¼‰"""
        try:
            # å°è¯•è·å–æ–‡ä»¶å¤§å°ä¿¡æ¯
            filesize = video_info.get('filesize')
            filesize_approx = video_info.get('filesize_approx')
            duration = video_info.get('duration')

            # ç¡®å®šæœ€ä½³çš„å¤§å°ä¼°ç®—
            estimated_size = None
            size_source = "æœªçŸ¥"

            if filesize and filesize > 0:
                estimated_size = filesize
                size_source = "ç²¾ç¡®"
            elif filesize_approx and filesize_approx > 0:
                estimated_size = filesize_approx
                size_source = "ä¼°ç®—"

            if estimated_size:
                # ä½¿ç”¨ç»Ÿä¸€çš„æ–‡ä»¶å¤§å°æ ¼å¼åŒ–å·¥å…·
                try:
                    from core.file_utils import FileUtils
                    size_str = FileUtils.format_file_size(estimated_size)
                except ImportError:
                    # å¤‡ç”¨æ ¼å¼åŒ–æ–¹æ¡ˆ
                    size_mb = estimated_size / (1024 * 1024)
                    size_gb = size_mb / 1024
                    if size_gb >= 1:
                        size_str = f"{size_gb:.2f} GB"
                    else:
                        size_str = f"{size_mb:.1f} MB"

                # è®°å½•æ–‡ä»¶å¤§å°ä¿¡æ¯
                logger.info(f"ğŸ“Š æ–‡ä»¶å¤§å°æ£€æµ‹: {title}")
                logger.info(f"   ğŸ“ é¢„ä¼°å¤§å°: {size_str} ({size_source})")

                # æä¾›ä¸‹è½½æ—¶é—´ä¼°ç®—ï¼ˆåŸºäºå¸¸è§ç½‘é€Ÿï¼‰
                if duration:
                    duration_str = f"{duration // 60}:{duration % 60:02d}"
                    logger.info(f"   â±ï¸ è§†é¢‘æ—¶é•¿: {duration_str}")

                # æ ¹æ®æ–‡ä»¶å¤§å°æä¾›å‹å¥½æç¤º
                size_mb = estimated_size / (1024 * 1024)
                if size_mb >= 5120:  # 5GB
                    logger.warning(f"âš ï¸ å¤§æ–‡ä»¶æé†’: æ–‡ä»¶è¾ƒå¤§ ({size_str})ï¼Œè¯·ç¡®ä¿æœ‰è¶³å¤Ÿçš„å­˜å‚¨ç©ºé—´å’Œç½‘ç»œå¸¦å®½")
                elif size_mb >= 2048:  # 2GB
                    logger.info(f"â„¹ï¸ æ–‡ä»¶æé†’: ä¸­ç­‰å¤§å°æ–‡ä»¶ ({size_str})ï¼Œé¢„è®¡éœ€è¦ä¸€äº›æ—¶é—´ä¸‹è½½")
                elif size_mb >= 100:
                    logger.info(f"â„¹ï¸ æ–‡ä»¶æé†’: æ ‡å‡†å¤§å°æ–‡ä»¶ ({size_str})")

                # æ£€æŸ¥å¯ç”¨ç£ç›˜ç©ºé—´
                self._check_available_disk_space(estimated_size, size_str)

            else:
                logger.info(f"ğŸ“Š æ–‡ä»¶å¤§å°æ£€æµ‹: {title}")
                logger.info(f"   ğŸ“ é¢„ä¼°å¤§å°: æ— æ³•è·å–å¤§å°ä¿¡æ¯")
                if duration:
                    duration_str = f"{duration // 60}:{duration % 60:02d}"
                    logger.info(f"   â±ï¸ è§†é¢‘æ—¶é•¿: {duration_str}")

        except Exception as e:
            logger.debug(f"æ–‡ä»¶å¤§å°æ£€æµ‹å¤±è´¥: {e}")

    def _check_available_disk_space(self, estimated_size: int, size_str: str):
        """æ£€æŸ¥å¯ç”¨ç£ç›˜ç©ºé—´"""
        try:
            import shutil

            # è·å–ä¸‹è½½ç›®å½•çš„ç£ç›˜ä½¿ç”¨æƒ…å†µ
            total, used, free = shutil.disk_usage(str(self.output_dir))

            # ä½¿ç”¨ç»Ÿä¸€çš„æ–‡ä»¶å¤§å°æ ¼å¼åŒ–å·¥å…·
            try:
                from core.file_utils import FileUtils
                free_str = FileUtils.format_file_size(free)
            except ImportError:
                # å¤‡ç”¨æ ¼å¼åŒ–æ–¹æ¡ˆ
                free_gb = free / (1024**3)
                free_str = f"{free_gb:.2f} GB"

            logger.info(f"   ğŸ’¾ å¯ç”¨ç©ºé—´: {free_str}")

            # æ£€æŸ¥ç©ºé—´æ˜¯å¦è¶³å¤Ÿï¼ˆé¢„ç•™20%ç¼“å†²ï¼‰
            required_space = estimated_size * 1.2  # é¢„ç•™20%ç©ºé—´

            if free < required_space:
                logger.warning(f"âš ï¸ ç£ç›˜ç©ºé—´è­¦å‘Š: å¯ç”¨ç©ºé—´å¯èƒ½ä¸è¶³")
                logger.warning(f"   éœ€è¦: {size_str} (+ 20%ç¼“å†²)")
                logger.warning(f"   å¯ç”¨: {free_str}")
            elif free < estimated_size * 2:  # å¦‚æœå¯ç”¨ç©ºé—´å°‘äºæ–‡ä»¶å¤§å°çš„2å€
                logger.info(f"â„¹ï¸ ç£ç›˜ç©ºé—´æé†’: å»ºè®®æ¸…ç†ä¸€äº›æ—§æ–‡ä»¶ä»¥é‡Šæ”¾æ›´å¤šç©ºé—´")

        except Exception as e:
            logger.debug(f"ç£ç›˜ç©ºé—´æ£€æŸ¥å¤±è´¥: {e}")

    def _handle_download_failure(self, download_id: str, error_msg: str):
        """å¤„ç†ä¸‹è½½å¤±è´¥ - ç»Ÿä¸€ä½¿ç”¨RetryManager"""
        try:
            # ä½¿ç”¨é‡è¯•ç®¡ç†å™¨åˆ¤æ–­æ˜¯å¦é‡è¯•
            should_retry = self.retry_manager.should_retry(download_id, error_msg)

            if should_retry:
                # å®‰æ’é‡è¯•
                self.retry_manager.schedule_retry(download_id, self._execute_download)

                # è·å–é‡è¯•ä¿¡æ¯ç”¨äºçŠ¶æ€æ˜¾ç¤º
                retry_info = self.retry_manager.get_retry_info(download_id)
                if retry_info:
                    retry_count = retry_info.get('retry_count', 0)
                    max_retries = self.retry_manager.retry_config.get('max_retries', 3)
                    self._update_download_status(download_id, 'retrying',
                                               error_message=f"é‡è¯•ä¸­ ({retry_count}/{max_retries}): {error_msg}")
                else:
                    self._update_download_status(download_id, 'retrying', error_message=f"å‡†å¤‡é‡è¯•: {error_msg}")
            else:
                # æ ‡è®°ä¸ºæœ€ç»ˆå¤±è´¥
                self._update_download_status(download_id, 'failed', error_message=error_msg)

                # å‘é€å¤±è´¥äº‹ä»¶
                self._emit_event('DOWNLOAD_FAILED', {
                    'download_id': download_id,
                    'error': error_msg
                })

                logger.error(f"âŒ ä¸‹è½½æœ€ç»ˆå¤±è´¥: {download_id} - {error_msg}")

        except Exception as e:
            logger.error(f"âŒ å¤„ç†ä¸‹è½½å¤±è´¥æ—¶å‡ºé”™: {e}")
            self._update_download_status(download_id, 'failed', error_message=f"å¤„ç†å¤±è´¥: {str(e)}")
    
    def _download_video(self, download_id: str, url: str, video_info: Dict[str, Any], options: Dict[str, Any]) -> Optional[str]:
        """ä¸‹è½½è§†é¢‘"""
        try:
            # æ£€æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
            if self._is_cancelled(download_id):
                logger.info(f"ğŸš« ä¸‹è½½å·²è¢«å–æ¶ˆï¼ˆå¼€å§‹ä¸‹è½½è§†é¢‘ï¼‰: {download_id}")
                return None

            if any(domain in url.lower() for domain in DownloadConstants.YOUTUBE_DOMAINS):
                # ä½¿ç”¨YouTubeç­–ç•¥
                logger.info(f"ğŸ¯ è°ƒç”¨YouTubeç­–ç•¥ä¸‹è½½: {download_id}")
                return self.youtube_strategies.download(download_id, url, video_info, options)
            else:
                # ä½¿ç”¨é€šç”¨ä¸‹è½½
                logger.info(f"ğŸŒ ä½¿ç”¨é€šç”¨ä¸‹è½½: {download_id}")
                return self._generic_download(download_id, url, video_info, options)

        except Exception as e:
            logger.error(f"âŒ è§†é¢‘ä¸‹è½½å¤±è´¥: {e}")
            return None
    
    def _generic_download(self, download_id: str, url: str, video_info: Dict[str, Any], options: Dict[str, Any]) -> Optional[str]:
        """é€šç”¨ä¸‹è½½æ–¹æ³•"""
        try:
            if not YT_DLP_AVAILABLE:
                raise ImportError("yt-dlp æ¨¡å—ä¸å¯ç”¨")

            # æ£€æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
            if self._is_cancelled(download_id):
                logger.info(f"ğŸš« ä¸‹è½½å·²è¢«å–æ¶ˆï¼ˆé€šç”¨ä¸‹è½½å¼€å§‹ï¼‰: {download_id}")
                return None

            # å‡†å¤‡ä¸‹è½½é…ç½®
            ydl_opts = self._prepare_download_options(url, options, download_id)

            # æ‰§è¡Œä¸‹è½½
            return self._execute_generic_download(download_id, url, ydl_opts, options)

        except yt_dlp.DownloadError as e:
            if "cancelled by user" in str(e):
                logger.info(f"ğŸš« ç”¨æˆ·å–æ¶ˆä¸‹è½½: {download_id}")
                return None
            else:
                logger.error(f"âŒ yt-dlpä¸‹è½½å¤±è´¥: {e}")
                return None
        except Exception as e:
            logger.error(f"âŒ é€šç”¨ä¸‹è½½å¤±è´¥: {e}")
            return None

    def _prepare_download_options(self, url: str, options: Dict[str, Any], download_id: str) -> Dict[str, Any]:
        """å‡†å¤‡ä¸‹è½½é€‰é¡¹é…ç½®"""
        if not YT_DLP_AVAILABLE:
            raise ImportError("yt-dlp æ¨¡å—ä¸å¯ç”¨")

        # ç”ŸæˆURLå“ˆå¸Œç”¨äºç»­ä¼ 
        url_hash = URLUtils.generate_url_hash(url)

        # æ™ºèƒ½è·¯å¾„é€‰æ‹©ï¼šéœ€è¦è½¬æ¢çš„æ–‡ä»¶ä½¿ç”¨ä¸´æ—¶ç›®å½•
        if self._needs_audio_conversion(options):
            # éœ€è¦è½¬æ¢ï¼Œä½¿ç”¨ä¸´æ—¶ç›®å½•
            output_template = str(self.temp_dir / f'{url_hash}.%(ext)s')
            logger.info(f"ğŸ”„ éœ€è¦éŸ³é¢‘è½¬æ¢ï¼Œä½¿ç”¨ä¸´æ—¶ç›®å½•: {self.temp_dir}")
        else:
            # ä¸éœ€è¦è½¬æ¢ï¼Œç›´æ¥ä½¿ç”¨æœ€ç»ˆç›®å½•
            output_template = str(self.output_dir / f'{url_hash}.%(ext)s')
            logger.info(f"ğŸ“ æ— éœ€è½¬æ¢ï¼Œç›´æ¥ä¸‹è½½åˆ°æœ€ç»ˆç›®å½•: {self.output_dir}")

        # åŸºç¡€é…ç½® - ä¼˜åŒ–ç»­ä¼ æ”¯æŒ
        ydl_opts = {
            'outtmpl': output_template,  # æ™ºèƒ½é€‰æ‹©è¾“å‡ºè·¯å¾„
            'continue_dl': True,  # æ˜ç¡®å¯ç”¨ç»­ä¼ 
            'nooverwrites': True,  # ä¸è¦†ç›–å·²å­˜åœ¨çš„æ–‡ä»¶
            'retries': DownloadConstants.DEFAULT_RETRIES,  # å¢åŠ é‡è¯•æ¬¡æ•°
            'fragment_retries': DownloadConstants.DEFAULT_FRAGMENT_RETRIES,  # åˆ†ç‰‡é‡è¯•æ¬¡æ•°
            'skip_unavailable_fragments': False,  # ä¸è·³è¿‡ä¸å¯ç”¨çš„åˆ†ç‰‡
            'allow_unplayable_formats': True,  # å…è®¸ä¸å¯æ’­æ”¾çš„æ ¼å¼
            'check_formats': False,  # è·³è¿‡æ ¼å¼æ£€æŸ¥ï¼Œå…è®¸ä¸å¸¸è§æ‰©å±•å
            'force_generic_extractor': True,  # å¼ºåˆ¶ä½¿ç”¨é€šç”¨æå–å™¨
            'prefer_free_formats': False,  # ä¸åå¥½å…è´¹æ ¼å¼
        }

        # åº”ç”¨é…ç½®æ–‡ä»¶é€‰é¡¹
        ydl_opts = self._apply_config_file_options(ydl_opts)

        # è®¾ç½®æ ¼å¼é€‰æ‹©å™¨
        ydl_opts = self._setup_format_selector(ydl_opts, url, options)

        # æ·»åŠ ä»£ç†é…ç½®
        proxy = self._get_proxy_config()
        if proxy:
            ydl_opts['proxy'] = proxy

        # åº”ç”¨PO Tokené…ç½® (åªå¯¹YouTubeæœ‰æ•ˆ)
        from core.po_token_manager import apply_po_token_to_ytdlp
        ydl_opts = apply_po_token_to_ytdlp(ydl_opts, url, "DownloadManager")

        # æ·»åŠ è¿›åº¦é’©å­
        ydl_opts['progress_hooks'] = [self._create_progress_hook(download_id)]

        # å¯¹äºæœ‰é—®é¢˜çš„URLï¼Œå°è¯•ç›´æ¥ä¸‹è½½è€Œä¸æ˜¯ä½¿ç”¨yt-dlpçš„å®‰å…¨æ£€æŸ¥
        if URLUtils.should_fix_extension(url):
            logger.info("ğŸ”§ æ£€æµ‹åˆ°é—®é¢˜URLï¼Œå°†å°è¯•ç›´æ¥ä¸‹è½½æ–¹å¼")
            # ç§»é™¤å¯èƒ½å¯¼è‡´é—®é¢˜çš„é€‰é¡¹
            ydl_opts.pop('check_formats', None)
            # æ·»åŠ å¼ºåˆ¶ä¸‹è½½é€‰é¡¹
            ydl_opts['force_json'] = False
            ydl_opts['simulate'] = False

        logger.info(f"ğŸ”„ ä½¿ç”¨ç»­ä¼ æ–‡ä»¶å: {url_hash} (æ¥è‡ªURL: {url[:50]}...)")

        return ydl_opts



    def _check_resume_support(self, url: str, proxies: Dict[str, str] = None) -> bool:
        """æ£€æµ‹æœåŠ¡å™¨æ˜¯å¦æ”¯æŒæ–­ç‚¹ç»­ä¼ """
        if not REQUESTS_AVAILABLE:
            logger.warning("âš ï¸ requests æ¨¡å—ä¸å¯ç”¨ï¼Œå‡è®¾ä¸æ”¯æŒæ–­ç‚¹ç»­ä¼ ")
            return False

        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'
            }

            # æ–¹æ³•1: æ£€æŸ¥HEADè¯·æ±‚çš„Accept-Rangeså¤´éƒ¨
            logger.debug("ğŸ” æ£€æµ‹æ–­ç‚¹ç»­ä¼ æ”¯æŒ - HEADè¯·æ±‚")
            response = requests.head(url, headers=headers, proxies=proxies, timeout=10)

            accept_ranges = response.headers.get('Accept-Ranges', '').lower()
            if accept_ranges == 'bytes':
                logger.debug("âœ… HEADè¯·æ±‚æ˜¾ç¤ºæ”¯æŒRange: bytes")

                # æ–¹æ³•2: å®é™…æµ‹è¯•å°èŒƒå›´Rangeè¯·æ±‚
                logger.debug("ğŸ” éªŒè¯Rangeè¯·æ±‚ - æµ‹è¯•å‰1KB")
                test_headers = headers.copy()
                test_headers['Range'] = 'bytes=0-1023'

                test_response = requests.get(url, headers=test_headers, proxies=proxies, timeout=10)

                if test_response.status_code == 206:
                    logger.debug("âœ… Rangeè¯·æ±‚æµ‹è¯•æˆåŠŸ - è¿”å›206")
                    return True
                elif test_response.status_code == 200:
                    logger.debug("âŒ Rangeè¯·æ±‚è¢«å¿½ç•¥ - è¿”å›å®Œæ•´æ–‡ä»¶")
                    return False
                else:
                    logger.debug(f"âš ï¸ Rangeè¯·æ±‚å¼‚å¸¸ - çŠ¶æ€ç : {test_response.status_code}")
                    return False
            elif accept_ranges == 'none':
                logger.debug("âŒ HEADè¯·æ±‚æ˜ç¡®ä¸æ”¯æŒRange")
                return False
            else:
                logger.debug("âš ï¸ HEADè¯·æ±‚æœªæ˜ç¡®Rangeæ”¯æŒï¼Œå°è¯•æµ‹è¯•")

                # æ²¡æœ‰æ˜ç¡®çš„Accept-Rangesï¼Œç›´æ¥æµ‹è¯•Rangeè¯·æ±‚
                test_headers = headers.copy()
                test_headers['Range'] = 'bytes=0-1023'

                test_response = requests.get(url, headers=test_headers, proxies=proxies, timeout=10)
                return test_response.status_code == 206

        except Exception as e:
            logger.warning(f"âš ï¸ æ–­ç‚¹ç»­ä¼ æ£€æµ‹å¤±è´¥ï¼Œå‡è®¾ä¸æ”¯æŒ: {e}")
            return False

    def _apply_config_file_options(self, base_opts: Dict[str, Any]) -> Dict[str, Any]:
        """åº”ç”¨é…ç½®æ–‡ä»¶é€‰é¡¹"""
        from .ytdlp_config_parser import get_ytdlp_config_options
        config_file_opts = get_ytdlp_config_options()
        if config_file_opts:
            # é…ç½®æ–‡ä»¶é€‰é¡¹ä¼˜å…ˆçº§è¾ƒé«˜ï¼ŒåŸºç¡€é€‰é¡¹ä½œä¸ºé»˜è®¤å€¼
            merged_opts = base_opts.copy()  # åŸºç¡€é€‰é¡¹ä½œä¸ºé»˜è®¤å€¼
            merged_opts.update(config_file_opts)  # é…ç½®æ–‡ä»¶é€‰é¡¹è¦†ç›–åŸºç¡€é€‰é¡¹
            logger.debug(f"âœ… åº”ç”¨yt-dlp.confé…ç½®: {len(config_file_opts)} ä¸ªé€‰é¡¹ï¼ˆé…ç½®æ–‡ä»¶ä¼˜å…ˆï¼‰")
            return merged_opts
        return base_opts

    def _setup_format_selector(self, ydl_opts: Dict[str, Any], url: str, options: Dict[str, Any]) -> Dict[str, Any]:
        """è®¾ç½®æ ¼å¼é€‰æ‹©å™¨"""
        quality = options.get('quality', 'best')
        audio_only = options.get('audio_only', False)

        # è·å–ä»£ç†é…ç½®ï¼ˆä¸€æ¬¡æ€§è·å–ï¼Œé¿å…é‡å¤è°ƒç”¨ï¼‰
        proxy = self._get_proxy_config()

        # è·å–å¹³å°é…ç½®ï¼ˆä¸€æ¬¡æ€§è·å–ï¼Œé¿å…é‡å¤å¯¼å…¥ï¼‰
        from .platforms import get_platform_for_url
        platform = get_platform_for_url(url)

        if audio_only or quality.startswith('audio_'):
            # ä¸‹è½½æœ€ä½³éŸ³é¢‘è´¨é‡ï¼Œåç»­è½¬æ¢
            ydl_opts['format'] = 'bestaudio/best'
            logger.info(f"ğŸµ éŸ³é¢‘ä¸‹è½½æ¨¡å¼: bestaudio/best")
        else:
            # æ£€æŸ¥æ˜¯å¦ä¸ºHLS/m3u8æµï¼Œç›´æ¥ä½¿ç”¨å¹³å°é…ç½®
            if url.lower().endswith('.m3u8') or 'm3u8' in url.lower():
                logger.info(f"ğŸ¯ æ£€æµ‹åˆ°HLS/m3u8æµï¼Œä½¿ç”¨å¹³å°é…ç½®")
                ydl_opts['format'] = platform.get_format_selector(quality, url)
                ydl_opts['noprogress'] = True
                logger.info(f"ğŸ”„ HLSæµä½¿ç”¨å¹³å°æ ¼å¼é€‰æ‹©å™¨: {ydl_opts['format']}")
            else:
                # ä¼˜å…ˆä½¿ç”¨å¹³å°ç‰¹å®šçš„æ ¼å¼é€‰æ‹©å™¨
                try:
                    platform_format = platform.get_format_selector(quality, url)
                    ydl_opts['format'] = platform_format
                    ydl_opts['noprogress'] = True  # é˜²æ­¢æ•°æ®ç±»å‹é”™è¯¯

                    logger.info(f"ğŸ¯ ä½¿ç”¨{platform.name}å¹³å°æ ¼å¼é€‰æ‹©å™¨: {platform_format}")

                except Exception as platform_error:
                    logger.warning(f"âš ï¸ å¹³å°æ ¼å¼é€‰æ‹©å™¨å¤±è´¥ï¼Œä½¿ç”¨æ™ºèƒ½é€‰æ‹©å™¨: {platform_error}")

                    # é™çº§åˆ°æ™ºèƒ½æ ¼å¼é€‰æ‹©å™¨
                    try:
                        from core.smart_format_selector import select_format_for_user
                        format_selector, reason, info = select_format_for_user(quality, url, proxy)
                        ydl_opts['format'] = format_selector
                        ydl_opts['noprogress'] = True  # é˜²æ­¢æ•°æ®ç±»å‹é”™è¯¯

                        logger.info(f"ğŸ† é™çº§ä½¿ç”¨æ™ºèƒ½æ ¼å¼é€‰æ‹©å™¨: {format_selector}")
                        logger.info(f"   é€‰æ‹©åŸå› : {reason}")

                    except Exception as smart_error:
                        logger.error(f"âŒ æ™ºèƒ½æ ¼å¼é€‰æ‹©å™¨ä¹Ÿå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ ¼å¼: {smart_error}")
                        ydl_opts['format'] = 'best/worst'
                        logger.info(f"ğŸ”„ ä½¿ç”¨é»˜è®¤æ ¼å¼é€‰æ‹©å™¨: best/worst")

        return ydl_opts

    def _create_progress_hook(self, download_id: str):
        """åˆ›å»ºè¿›åº¦é’©å­å‡½æ•°"""
        def progress_hook(d):
            if self._is_cancelled(download_id):
                logger.info(f"ğŸš« ä¸‹è½½å·²è¢«å–æ¶ˆï¼ˆä¸‹è½½è¿›è¡Œä¸­ï¼‰: {download_id}")
                if YT_DLP_AVAILABLE:
                    raise yt_dlp.DownloadError("Download cancelled by user")
                else:
                    raise Exception("Download cancelled by user")

            if d.get('status') == 'downloading':
                # æ›´æ–°è¿›åº¦ - å®‰å…¨çš„ç±»å‹å¤„ç†
                try:
                    total = d.get('total_bytes') or d.get('total_bytes_estimate')
                    downloaded = d.get('downloaded_bytes')

                    # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®ï¼Œé¿å… "can't multiply sequence by non-int" é”™è¯¯
                    if total is not None and downloaded is not None:
                        try:
                            total = float(total) if total else 0.0
                            downloaded = float(downloaded) if downloaded else 0.0

                            if total > 0:
                                # ä½¿ç”¨ç»Ÿä¸€çš„è¿›åº¦è®¡ç®—å·¥å…·ï¼Œå¸¦å¹³æ»‘åŒ–å¤„ç†
                                from core.file_utils import ProgressUtils
                                progress = ProgressUtils.calculate_smooth_progress(int(downloaded), int(total), download_id)

                                # ğŸ”§ æ€»æ˜¯æ›´æ–°è¿›åº¦çŠ¶æ€ï¼ˆWebç•Œé¢éœ€è¦å®æ—¶è¿›åº¦ï¼‰
                                self._update_download_status(download_id, 'downloading', progress)

                                # åªåœ¨è¿›åº¦æœ‰æ˜¾è‘—å˜åŒ–æ—¶è®°å½•æ—¥å¿—ï¼ˆå‡å°‘æ—¥å¿—å™ªéŸ³ï¼‰
                                if progress % DownloadConstants.PROGRESS_LOG_INTERVAL == 0:
                                    logger.info(f"ğŸ“Š ä¸‹è½½è¿›åº¦: {download_id} - {progress}%")
                        except (ValueError, TypeError, ZeroDivisionError) as e:
                            # è®°å½•å…·ä½“çš„ç±»å‹è½¬æ¢é”™è¯¯ï¼Œä¾¿äºè°ƒè¯•
                            logger.debug(f"è¿›åº¦è®¡ç®—ç±»å‹è½¬æ¢é”™è¯¯: {e}")
                except Exception as e:
                    # è®°å½•è¿›åº¦é’©å­çš„å…¶ä»–å¼‚å¸¸ï¼Œä¾¿äºè°ƒè¯•
                    logger.debug(f"è¿›åº¦é’©å­å¼‚å¸¸: {e}")

        return progress_hook

    def _execute_generic_download(self, download_id: str, url: str, ydl_opts: Dict[str, Any], options: Dict[str, Any] = None) -> Optional[str]:
        """æ‰§è¡Œé€šç”¨ä¸‹è½½"""
        if not YT_DLP_AVAILABLE:
            raise ImportError("yt-dlp æ¨¡å—ä¸å¯ç”¨")

        # å¯¹äºæœ‰é—®é¢˜çš„URLï¼Œå°è¯•ç›´æ¥ä¸‹è½½
        if URLUtils.should_fix_extension(url):
            logger.info("ğŸ”§ å°è¯•ç›´æ¥ä¸‹è½½æ–¹å¼ç»•è¿‡æ‰©å±•åæ£€æŸ¥")
            try:
                return self._direct_download_fallback(download_id, url, ydl_opts, options)
            except Exception as e:
                logger.warning(f"âš ï¸ ç›´æ¥ä¸‹è½½å¤±è´¥ï¼Œå›é€€åˆ°æ ‡å‡†æ–¹å¼: {e}")

        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            ydl.download([url])

        # æœ€åæ£€æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
        if self._is_cancelled(download_id):
            logger.info(f"ğŸš« ä¸‹è½½å·²è¢«å–æ¶ˆï¼ˆä¸‹è½½å®Œæˆåï¼‰: {download_id}")
            return None

        # æŸ¥æ‰¾ä¸‹è½½çš„æ–‡ä»¶ï¼ˆä½¿ç”¨URLå“ˆå¸Œï¼‰
        url_hash = URLUtils.generate_url_hash(url)
        return self._find_downloaded_file(url_hash, options)

    def _direct_download_fallback(self, download_id: str, url: str, ydl_opts: Dict[str, Any], options: Dict[str, Any] = None) -> Optional[str]:
        """ç›´æ¥ä¸‹è½½å¤‡ç”¨æ–¹æ¡ˆï¼Œç»•è¿‡yt-dlpçš„æ‰©å±•åæ£€æŸ¥"""
        if not REQUESTS_AVAILABLE:
            raise ImportError("requests æ¨¡å—ä¸å¯ç”¨")

        try:
            # ä»URLä¸­æå–çœŸå®çš„æ–‡ä»¶å
            real_filename = URLUtils.extract_filename_from_url(url)
            if not real_filename:
                # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨URLå“ˆå¸Œ + æ¨æµ‹çš„æ‰©å±•å
                url_hash = URLUtils.generate_url_hash(url)
                if '.mp4' in url:
                    real_filename = f"{url_hash}.mp4"
                elif '.avi' in url:
                    real_filename = f"{url_hash}.avi"
                else:
                    real_filename = f"{url_hash}.mp4"  # é»˜è®¤ä½¿ç”¨mp4

            logger.info(f"ğŸ”§ ç›´æ¥ä¸‹è½½æ–‡ä»¶: {real_filename}")

            # å‡†å¤‡ä¸‹è½½è·¯å¾„
            url_hash = URLUtils.generate_url_hash(url)
            if self._needs_audio_conversion(options):
                output_path = self.temp_dir / real_filename
            else:
                output_path = self.output_dir / real_filename

            # è·å–ä»£ç†é…ç½®
            proxy = self._get_proxy_config()
            proxies = {'http': proxy, 'https': proxy} if proxy else None

            # æ£€æµ‹æœåŠ¡å™¨æ˜¯å¦æ”¯æŒæ–­ç‚¹ç»­ä¼ 
            resume_support = self._check_resume_support(url, proxies)
            logger.info(f"ğŸ” æœåŠ¡å™¨æ–­ç‚¹ç»­ä¼ æ”¯æŒ: {'âœ… æ”¯æŒ' if resume_support else 'âŒ ä¸æ”¯æŒ'}")

            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨éƒ¨åˆ†ä¸‹è½½çš„æ–‡ä»¶ï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰
            resume_pos = 0
            if output_path.exists() and resume_support:
                resume_pos = output_path.stat().st_size
                logger.info(f"ğŸ”„ æ£€æµ‹åˆ°éƒ¨åˆ†æ–‡ä»¶ï¼Œä» {resume_pos / (1024*1024):.1f}MB å¤„ç»­ä¼ ")
            elif output_path.exists() and not resume_support:
                # æœåŠ¡å™¨ä¸æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œåˆ é™¤éƒ¨åˆ†æ–‡ä»¶é‡æ–°å¼€å§‹
                logger.info("ğŸ—‘ï¸ æœåŠ¡å™¨ä¸æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œåˆ é™¤éƒ¨åˆ†æ–‡ä»¶é‡æ–°ä¸‹è½½")
                output_path.unlink()
                resume_pos = 0

            # ç›´æ¥ä¸‹è½½æ–‡ä»¶ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36'
            }

            # å¦‚æœæœ‰éƒ¨åˆ†æ–‡ä»¶ä¸”æœåŠ¡å™¨æ”¯æŒï¼Œæ·»åŠ Rangeå¤´éƒ¨è¿›è¡Œæ–­ç‚¹ç»­ä¼ 
            if resume_pos > 0 and resume_support:
                headers['Range'] = f'bytes={resume_pos}-'
                logger.info(f"ğŸ“¡ å‘é€Rangeè¯·æ±‚: bytes={resume_pos}-")

            # ä½¿ç”¨æ›´é•¿çš„è¶…æ—¶æ—¶é—´å’Œé‡è¯•é…ç½®
            session = requests.Session()
            session.proxies = proxies

            # é…ç½®é‡è¯•é€‚é…å™¨
            from requests.adapters import HTTPAdapter
            from urllib3.util.retry import Retry

            retry_strategy = Retry(
                total=3,
                backoff_factor=1,
                status_forcelist=[429, 500, 502, 503, 504],
                allowed_methods=["HEAD", "GET", "OPTIONS"]
            )

            adapter = HTTPAdapter(max_retries=retry_strategy)
            session.mount("http://", adapter)
            session.mount("https://", adapter)

            response = session.get(url, headers=headers, stream=True, timeout=(30, 300))  # è¿æ¥30sï¼Œè¯»å–300s
            response.raise_for_status()

            # è·å–æ–‡ä»¶æ€»å¤§å°ï¼ˆå¤„ç†æ–­ç‚¹ç»­ä¼ ï¼‰
            if response.status_code == 206:  # éƒ¨åˆ†å†…å®¹å“åº”
                # ä»Content-Rangeå¤´éƒ¨è·å–æ€»å¤§å°
                content_range = response.headers.get('content-range', '')
                if content_range:
                    # æ ¼å¼: bytes 200-1023/1024
                    total_size = int(content_range.split('/')[-1])
                else:
                    total_size = int(response.headers.get('content-length', 0)) + resume_pos
            else:
                total_size = int(response.headers.get('content-length', 0))

            downloaded_size = resume_pos  # ä»å·²ä¸‹è½½çš„ä½ç½®å¼€å§‹è®¡ç®—
            last_progress = int((downloaded_size / total_size) * 100) if total_size > 0 else 0

            logger.info(f"ğŸ“ æ–‡ä»¶æ€»å¤§å°: {total_size / (1024*1024):.1f}MB" if total_size > 0 else "ğŸ“ æ–‡ä»¶å¤§å°æœªçŸ¥")
            if resume_pos > 0:
                logger.info(f"ğŸ”„ æ–­ç‚¹ç»­ä¼ : å·²ä¸‹è½½ {resume_pos / (1024*1024):.1f}MBï¼Œç»§ç»­ä¸‹è½½")

            # ä¿å­˜æ–‡ä»¶å¹¶æ˜¾ç¤ºè¿›åº¦ï¼ˆæ–­ç‚¹ç»­ä¼ æ¨¡å¼ï¼‰
            file_mode = 'ab' if resume_pos > 0 else 'wb'
            with open(output_path, file_mode) as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        downloaded_size += len(chunk)

                        # è®¡ç®—å¹¶å‘é€è¿›åº¦ï¼ˆåªåœ¨è¿›åº¦å˜åŒ–æ—¶æ›´æ–°ï¼‰
                        if total_size > 0:
                            progress = int((downloaded_size / total_size) * 100)
                            # åªåœ¨è¿›åº¦å˜åŒ–è¶…è¿‡1%æ—¶æ›´æ–°ï¼Œå‡å°‘é¢‘ç¹æ›´æ–°
                            if progress != last_progress and (progress - last_progress >= 1 or progress == 100):
                                self._update_download_status(download_id, "downloading", progress)
                                last_progress = progress

                        # æ¯ä¸‹è½½1MBè®°å½•ä¸€æ¬¡æ—¥å¿—
                        if downloaded_size % (1024 * 1024) == 0 or downloaded_size == total_size:
                            mb_downloaded = downloaded_size / (1024 * 1024)
                            if total_size > 0:
                                total_mb = total_size / (1024 * 1024)
                                progress = int((downloaded_size / total_size) * 100)
                                logger.info(f"ğŸ“¥ ç›´æ¥ä¸‹è½½è¿›åº¦: {mb_downloaded:.1f}MB / {total_mb:.1f}MB ({progress}%)")
                            else:
                                logger.info(f"ğŸ“¥ ç›´æ¥ä¸‹è½½è¿›åº¦: {mb_downloaded:.1f}MB")

                        # æ£€æŸ¥æ˜¯å¦è¢«å–æ¶ˆ
                        if self._is_cancelled(download_id):
                            logger.info(f"ğŸš« ç›´æ¥ä¸‹è½½å·²è¢«å–æ¶ˆ: {download_id}")
                            output_path.unlink(missing_ok=True)
                            return None

            # å‘é€å®Œæˆè¿›åº¦
            self._update_download_status(download_id, "downloading", 100)
            logger.info(f"âœ… ç›´æ¥ä¸‹è½½å®Œæˆ: {output_path} ({downloaded_size / (1024*1024):.1f}MB)")
            return str(output_path)

        except Exception as e:
            error_msg = str(e)
            logger.error(f"âŒ ç›´æ¥ä¸‹è½½å¤±è´¥: {error_msg}")

            # æ£€æŸ¥æ˜¯å¦æ˜¯ç½‘ç»œè¿æ¥é—®é¢˜
            if any(keyword in error_msg.lower() for keyword in ['connection', 'timeout', 'incomplete', 'broken']):
                # æ ¹æ®æœåŠ¡å™¨æ”¯æŒæƒ…å†µå†³å®šæ˜¯å¦ä¿ç•™éƒ¨åˆ†æ–‡ä»¶
                if output_path.exists():
                    current_size = output_path.stat().st_size
                    if resume_support:
                        logger.info(f"ğŸ’¾ ä¿ç•™éƒ¨åˆ†æ–‡ä»¶ç”¨äºç»­ä¼ : {current_size / (1024*1024):.1f}MB")
                        # æŠ›å‡ºç‰¹å®šçš„ç½‘ç»œé”™è¯¯ï¼Œè®©é‡è¯•æœºåˆ¶å¤„ç†
                        raise ConnectionError(f"ç½‘ç»œè¿æ¥ä¸­æ–­ï¼Œå·²ä¿å­˜ {current_size / (1024*1024):.1f}MBï¼Œæ”¯æŒç»­ä¼ ")
                    else:
                        logger.info(f"ğŸ—‘ï¸ æœåŠ¡å™¨ä¸æ”¯æŒç»­ä¼ ï¼Œåˆ é™¤éƒ¨åˆ†æ–‡ä»¶: {current_size / (1024*1024):.1f}MB")
                        output_path.unlink(missing_ok=True)
                        # æŠ›å‡ºç½‘ç»œé”™è¯¯ï¼Œä½†ä¸æåŠç»­ä¼ 
                        raise ConnectionError("ç½‘ç»œè¿æ¥ä¸­æ–­ï¼ŒæœåŠ¡å™¨ä¸æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œéœ€è¦é‡æ–°ä¸‹è½½")
                else:
                    raise ConnectionError("ç½‘ç»œè¿æ¥ä¸­æ–­")
            else:
                # å…¶ä»–é”™è¯¯ï¼Œåˆ é™¤éƒ¨åˆ†æ–‡ä»¶
                if output_path.exists():
                    output_path.unlink(missing_ok=True)
                    logger.info("ğŸ—‘ï¸ åˆ é™¤æŸåçš„éƒ¨åˆ†æ–‡ä»¶")
                raise



    def _find_downloaded_file(self, url_hash: str, options: Dict[str, Any] = None) -> Optional[str]:
        """å®‰å…¨åœ°æŸ¥æ‰¾ä¸‹è½½çš„æ–‡ä»¶ - æ”¯æŒä¸´æ—¶ç›®å½•å’Œæœ€ç»ˆç›®å½•"""
        try:
            # ä½¿ç”¨æ›´å®‰å…¨çš„æ–‡ä»¶åŒ¹é…é€»è¾‘
            matched_files = []

            # ç¡®å®šæœç´¢ç›®å½•ï¼šæ˜ç¡®çš„å•ä¸€ç›®å½•æœç´¢
            if options and self._needs_audio_conversion(options):
                search_dir = self.temp_dir
                logger.debug(f"ğŸ” æœç´¢éœ€è¦è½¬æ¢çš„æ–‡ä»¶: {search_dir}")
            else:
                search_dir = self.output_dir
                logger.debug(f"ğŸ” æœç´¢æ— éœ€è½¬æ¢çš„æ–‡ä»¶: {search_dir}")

            # åœ¨æŒ‡å®šç›®å½•æœç´¢æ–‡ä»¶
            if search_dir.exists():
                for file_path in search_dir.iterdir():
                    if (file_path.is_file() and
                        file_path.name.startswith(url_hash + '.') and
                        not file_path.name.endswith('.part') and
                        not file_path.name.endswith('.tmp')):
                        matched_files.append(file_path)

            if matched_files:
                # å¦‚æœæœ‰å¤šä¸ªåŒ¹é…æ–‡ä»¶ï¼Œé€‰æ‹©æœ€æ–°çš„
                latest_file = max(matched_files, key=lambda f: f.stat().st_mtime)
                logger.info(f"âœ… æ‰¾åˆ°ä¸‹è½½æ–‡ä»¶: {latest_file} (ç›®å½•: {latest_file.parent.name})")
                return str(latest_file)

            logger.debug(f"ğŸ” æœªæ‰¾åˆ°åŒ¹é…çš„ä¸‹è½½æ–‡ä»¶: {url_hash}")
            return None

        except Exception as e:
            logger.error(f"âŒ æŸ¥æ‰¾ä¸‹è½½æ–‡ä»¶å¤±è´¥: {e}")
            return None

    def _find_partial_files(self, url_hash: str) -> List[Path]:
        """å®‰å…¨åœ°æŸ¥æ‰¾éƒ¨åˆ†ä¸‹è½½çš„æ–‡ä»¶"""
        try:
            partial_files = []

            # éå†è¾“å‡ºç›®å½•ï¼ŒæŸ¥æ‰¾éƒ¨åˆ†æ–‡ä»¶
            for file_path in self.output_dir.iterdir():
                if (file_path.is_file() and
                    file_path.name.startswith(url_hash + '.') and
                    (file_path.name.endswith('.part') or
                     file_path.name.endswith('.tmp') or
                     file_path.stat().st_size > 0)):  # æœ‰å†…å®¹çš„æ–‡ä»¶
                    partial_files.append(file_path)

            return partial_files

        except Exception as e:
            logger.error(f"âŒ æŸ¥æ‰¾éƒ¨åˆ†æ–‡ä»¶å¤±è´¥: {e}")
            return []

    def _validate_config_int(self, value: Any, name: str, min_val: int, max_val: int) -> int:
        """éªŒè¯æ•´æ•°é…ç½®å€¼"""
        try:
            int_value = int(value)
            if min_val <= int_value <= max_val:
                return int_value
            else:
                logger.warning(f"âš ï¸ é…ç½® {name} å€¼ {int_value} è¶…å‡ºèŒƒå›´ [{min_val}, {max_val}]ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                return min(max(int_value, min_val), max_val)
        except (ValueError, TypeError):
            logger.warning(f"âš ï¸ é…ç½® {name} å€¼ {value} æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤å€¼ {min_val}")
            return min_val

    def _validate_config_path(self, value: Any, name: str) -> Path:
        """éªŒè¯è·¯å¾„é…ç½®å€¼"""
        try:
            path = Path(str(value))
            # ç¡®ä¿è·¯å¾„æ˜¯ç»å¯¹è·¯å¾„
            if not path.is_absolute():
                # ç›¸å¯¹äºå½“å‰å·¥ä½œç›®å½•
                path = Path.cwd() / path
            return path
        except Exception as e:
            logger.warning(f"âš ï¸ é…ç½® {name} è·¯å¾„ {value} æ— æ•ˆ: {e}ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„")
            return Path.cwd() / 'downloads' if name == 'output_dir' else Path.cwd() / 'temp'

    def _update_stats(self, event_type: str, **kwargs):
        """æ›´æ–°æ€§èƒ½ç»Ÿè®¡"""
        try:
            with self.lock:
                if event_type == 'download_started':
                    self.stats['total_downloads'] += 1
                elif event_type == 'download_completed':
                    self.stats['successful_downloads'] += 1
                    # æ›´æ–°ä¸‹è½½å­—èŠ‚æ•°
                    file_size = kwargs.get('file_size', 0)
                    if file_size:
                        self.stats['total_bytes_downloaded'] += file_size
                elif event_type == 'download_failed':
                    self.stats['failed_downloads'] += 1
                elif event_type == 'download_cancelled':
                    self.stats['cancelled_downloads'] += 1
        except Exception as e:
            logger.debug(f"ç»Ÿè®¡æ›´æ–°å¤±è´¥: {e}")

    def get_performance_stats(self) -> Dict[str, Any]:
        """è·å–ç®€åŒ–çš„æ€§èƒ½ç»Ÿè®¡ - åªè¿”å›å…³é”®æŒ‡æ ‡"""
        try:
            with self.lock:
                total = max(self.stats['total_downloads'], 1)
                success_rate = (self.stats['successful_downloads'] / total) * 100
                total_mb = self.stats['total_bytes_downloaded'] / 1024 / 1024

                return {
                    'total_downloads': self.stats['total_downloads'],
                    'success_rate': round(success_rate, 1),
                    'total_mb': round(total_mb, 1),
                    'failed_downloads': self.stats['failed_downloads']
                }
        except Exception as e:
            logger.error(f"âŒ è·å–æ€§èƒ½ç»Ÿè®¡å¤±è´¥: {e}")
            return {
                'total_downloads': 0,
                'success_rate': 0.0,
                'total_mb': 0.0,
                'failed_downloads': 0
            }

    def _needs_audio_conversion(self, options: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦éŸ³é¢‘è½¬æ¢"""
        quality = options.get('quality', 'best')
        audio_only = options.get('audio_only', False)
        return audio_only or quality.startswith('audio_')

    def _convert_to_audio(self, input_path: str, options: Dict[str, Any]) -> Optional[str]:
        """è½¬æ¢ä¸ºéŸ³é¢‘æ ¼å¼ - æ”¯æŒä¸´æ—¶ç›®å½•åˆ°æœ€ç»ˆç›®å½•çš„æµç¨‹"""
        try:
            quality = options.get('quality', 'best')

            # è§£æéŸ³é¢‘æ ¼å¼å’Œè´¨é‡
            if quality.startswith('audio_'):
                parts = quality.split('_')
                if len(parts) >= 3:
                    audio_format = parts[1]  # mp3, aac, flac
                    audio_quality = parts[2]  # high, medium, low
                else:
                    audio_format = 'mp3'
                    audio_quality = 'medium'
            else:
                # é»˜è®¤éŸ³é¢‘æ ¼å¼
                audio_format = 'mp3'
                audio_quality = 'medium'

            input_file = Path(input_path)

            # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å·²ç»æ˜¯ç›®æ ‡æ ¼å¼
            current_extension = input_file.suffix.lower().lstrip('.')
            target_extension = audio_format.lower()

            # åˆ¤æ–­æ˜¯å¦éœ€è¦å®é™…è½¬æ¢
            if current_extension == target_extension:
                logger.info(f"âœ… æ–‡ä»¶å·²ç»æ˜¯ç›®æ ‡æ ¼å¼ {audio_format.upper()}ï¼Œæ— éœ€è½¬æ¢: {input_file.name}")
                # å¦‚æœæ–‡ä»¶åœ¨ä¸´æ—¶ç›®å½•ï¼Œéœ€è¦ç§»åŠ¨åˆ°æœ€ç»ˆç›®å½•
                if str(input_file.parent) == str(self.temp_dir):
                    final_path = self.output_dir / input_file.name
                    try:
                        input_file.rename(final_path)
                        logger.info(f"ğŸ“ æ–‡ä»¶å·²ç§»åŠ¨åˆ°æœ€ç»ˆç›®å½•: {final_path.name}")
                        return str(final_path)
                    except Exception as e:
                        logger.error(f"âŒ ç§»åŠ¨æ–‡ä»¶å¤±è´¥: {e}")
                        return input_path
                else:
                    return input_path

            # éœ€è¦è½¬æ¢ï¼šåœ¨ä¸´æ—¶ç›®å½•è¿›è¡Œè½¬æ¢ï¼Œç„¶åç§»åŠ¨åˆ°æœ€ç»ˆç›®å½•
            temp_output_path = str(input_file.parent / f"{input_file.stem}.{audio_format}")

            # åŒé‡æ£€æŸ¥ï¼šå¦‚æœè·¯å¾„ç›¸åŒï¼Œæ·»åŠ åç¼€é¿å…å†²çª
            if temp_output_path == input_path:
                temp_output_path = str(input_file.parent / f"{input_file.stem}_converted.{audio_format}")
                logger.warning(f"âš ï¸ è¾“å…¥è¾“å‡ºè·¯å¾„ç›¸åŒï¼Œä½¿ç”¨ä¸´æ—¶æ–‡ä»¶å: {Path(temp_output_path).name}")

            # ä½¿ç”¨FFmpegå·¥å…·è½¬æ¢
            logger.info(f"ğŸ”„ å¼€å§‹éŸ³é¢‘è½¬æ¢: {input_file.name} -> {Path(temp_output_path).name}")
            success = self.ffmpeg_tools.extract_audio(
                input_path=input_path,
                output_path=temp_output_path,
                format=audio_format,
                quality=audio_quality
            )

            if success and Path(temp_output_path).exists():
                logger.info(f"âœ… éŸ³é¢‘è½¬æ¢æˆåŠŸ: {audio_format} ({audio_quality})")

                # ç§»åŠ¨è½¬æ¢åçš„æ–‡ä»¶åˆ°æœ€ç»ˆç›®å½•
                temp_file = Path(temp_output_path)
                final_path = self.output_dir / temp_file.name

                try:
                    temp_file.rename(final_path)
                    logger.info(f"ğŸ“ è½¬æ¢åæ–‡ä»¶å·²ç§»åŠ¨åˆ°æœ€ç»ˆç›®å½•: {final_path.name}")

                    # æ¸…ç†åŸå§‹æ–‡ä»¶
                    try:
                        Path(input_path).unlink()
                        logger.debug(f"ğŸ—‘ï¸ æ¸…ç†åŸå§‹æ–‡ä»¶: {Path(input_path).name}")
                    except:
                        pass

                    return str(final_path)
                except Exception as e:
                    logger.error(f"âŒ ç§»åŠ¨è½¬æ¢åæ–‡ä»¶å¤±è´¥: {e}")
                    return temp_output_path
            else:
                logger.error(f"âŒ éŸ³é¢‘è½¬æ¢å¤±è´¥")
                return None

        except Exception as e:
            logger.error(f"âŒ éŸ³é¢‘è½¬æ¢å¼‚å¸¸: {e}")
            return None

    def _get_audio_bitrate(self, audio_format: str, audio_quality: str) -> str:
        """è·å–éŸ³é¢‘æ¯”ç‰¹ç‡"""
        bitrate_map = {
            'mp3': {
                'high': '320',
                'medium': '192',
                'low': '128'
            },
            'aac': {
                'high': '256',
                'medium': '128',
                'low': '96'
            },
            'flac': {
                'high': '0',  # æ— æŸ
                'medium': '0',
                'low': '0'
            },
            'ogg': {
                'high': '256',
                'medium': '128',
                'low': '96'
            }
        }

        return bitrate_map.get(audio_format, {}).get(audio_quality, '192')

    def _apply_smart_filename(self, file_path: str, video_info: Dict[str, Any], options: Dict[str, Any]) -> Optional[str]:
        """åº”ç”¨æ™ºèƒ½æ–‡ä»¶å"""
        try:
            if options.get('custom_filename'):
                return self.filename_processor.apply_custom_filename(file_path, options['custom_filename'])
            else:
                title = video_info.get('title', 'Unknown')
                download_id = Path(file_path).stem.split('.')[0]
                file_parent = Path(file_path).parent

                # æ·»åŠ è°ƒè¯•æ—¥å¿—
                logger.info(f"ğŸ”§ æ™ºèƒ½æ–‡ä»¶åå¤„ç†è°ƒè¯•:")
                logger.info(f"   file_path: {file_path}")
                logger.info(f"   download_id: {download_id}")
                logger.info(f"   file_parent: {file_parent}")
                logger.info(f"   file_parent.exists(): {file_parent.exists()}")

                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦çœŸçš„å­˜åœ¨
                actual_file = Path(file_path)
                logger.info(f"   actual_file.exists(): {actual_file.exists()}")

                return self.filename_processor.apply_smart_filename_to_all(download_id, title, file_parent)
        except Exception as e:
            logger.error(f"âŒ åº”ç”¨æ™ºèƒ½æ–‡ä»¶åå¤±è´¥: {e}")
            return None

    def _get_proxy_config(self) -> Optional[str]:
        """è·å–ä»£ç†é…ç½® - ä½¿ç”¨ç»Ÿä¸€çš„é…ç½®ç®¡ç†å™¨"""
        return ConfigManager.get_proxy_config()



    def _save_to_database(self, download_id: str, url: str):
        """ä¿å­˜åˆ°æ•°æ®åº“"""
        try:
            get_database = ConfigManager.get_database_func()
            if not get_database:
                logger.debug("æ•°æ®åº“æ¨¡å—ä¸å¯ç”¨ï¼Œè·³è¿‡ä¿å­˜")
                return
            db = get_database()
            db.save_download_record(download_id, url)
        except Exception as e:
            logger.warning(f"âš ï¸ ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥: {e}")

    def _update_database_status(self, download_id: str, status: str, **kwargs):
        """æ›´æ–°æ•°æ®åº“çŠ¶æ€"""
        try:
            get_database = ConfigManager.get_database_func()
            if not get_database:
                logger.debug("æ•°æ®åº“æ¨¡å—ä¸å¯ç”¨ï¼Œè·³è¿‡çŠ¶æ€æ›´æ–°")
                return
            db = get_database()
            db.update_download_status(download_id, status, **kwargs)
        except Exception as e:
            logger.warning(f"âš ï¸ æ›´æ–°æ•°æ®åº“çŠ¶æ€å¤±è´¥: {e}")

    def _emit_event(self, event_name: str, data: Dict[str, Any]):
        """å‘é€äº‹ä»¶"""
        try:
            from core.events import emit, Events
            event = getattr(Events, event_name, None)
            if event:
                logger.info(f"ğŸ“¡ å‘é€äº‹ä»¶: {event_name} - {data.get('download_id', 'N/A')}")
                emit(event, data)
            else:
                logger.warning(f"âš ï¸ æœªçŸ¥äº‹ä»¶ç±»å‹: {event_name}")
        except Exception as e:
            logger.error(f"âŒ å‘é€äº‹ä»¶å¤±è´¥: {event_name} - {e}")
            import traceback
            traceback.print_exc()

    def _update_download_status(self, download_id: str, status: str, progress: int = None, **kwargs):
        """æ›´æ–°ä¸‹è½½çŠ¶æ€"""
        try:
            # å…ˆè·å–éœ€è¦çš„æ•°æ®ï¼Œå‡å°‘é”çš„æŒæœ‰æ—¶é—´
            download_info = None
            with self.lock:
                if download_id in self.downloads:
                    self.downloads[download_id]['status'] = status
                    if progress is not None:
                        self.downloads[download_id]['progress'] = progress
                    for key, value in kwargs.items():
                        self.downloads[download_id][key] = value
                    # è·å–ä¸‹è½½ä¿¡æ¯çš„å‰¯æœ¬ï¼Œç”¨äºäº‹ä»¶å‘é€
                    download_info = self.downloads[download_id].copy()

            # åœ¨é”å¤–æ‰§è¡Œè€—æ—¶æ“ä½œ
            # æ›´æ–°æ•°æ®åº“
            self._update_database_status(download_id, status, **kwargs)

            # å‘é€çŠ¶æ€å˜æ›´äº‹ä»¶
            if status == 'completed' and download_info:
                # æ›´æ–°ç»Ÿè®¡
                self._update_stats('download_completed', file_size=kwargs.get('file_size', 0))

                self._emit_event('DOWNLOAD_COMPLETED', {
                    'download_id': download_id,
                    'file_path': kwargs.get('file_path'),
                    'title': download_info.get('title', 'Unknown'),
                    'file_size': kwargs.get('file_size')
                })
                logger.info(f"ğŸ“¡ å‘é€ä¸‹è½½å®Œæˆäº‹ä»¶: {download_id}")
            elif status == 'failed':
                # æ›´æ–°ç»Ÿè®¡
                self._update_stats('download_failed')
            elif status == 'cancelled':
                # æ›´æ–°ç»Ÿè®¡
                self._update_stats('download_cancelled')
            elif status in ['downloading', 'retrying']:
                # å‘é€è¿›åº¦äº‹ä»¶
                self._emit_event('DOWNLOAD_PROGRESS', {
                    'download_id': download_id,
                    'status': status,
                    'progress': progress or 0
                })

        except Exception as e:
            logger.error(f"âŒ æ›´æ–°ä¸‹è½½çŠ¶æ€å¤±è´¥: {e}")

    def get_active_downloads(self) -> List[Dict]:
        """è·å–æ´»è·ƒçš„ä¸‹è½½ä»»åŠ¡ï¼ˆæ­£åœ¨è¿›è¡Œä¸­çš„ï¼‰"""
        try:
            with self.lock:
                active_downloads = []
                for download_id, download_info in self.downloads.items():
                    if download_info.get('status') in ['pending', 'downloading']:
                        active_downloads.append({
                            'id': download_id,
                            'status': download_info.get('status'),
                            'title': download_info.get('title'),
                            'url': download_info.get('url'),
                            'progress': download_info.get('progress', 0),
                            'created_at': download_info.get('created_at')
                        })
                return active_downloads
        except Exception as e:
            logger.error(f"âŒ è·å–æ´»è·ƒä¸‹è½½å¤±è´¥: {e}")
            return []

    def get_system_status(self) -> Dict[str, Any]:
        """è·å–ç®€åŒ–çš„ç³»ç»ŸçŠ¶æ€ - åªè¿”å›å…³é”®ä¿¡æ¯"""
        try:
            # è·å–åŸºç¡€çŠ¶æ€
            active_downloads = len([d for d in self.downloads.values() if d['status'] in ['pending', 'downloading']])

            # è·å–å¥åº·æ£€æŸ¥
            health = self.health_check()

            # è·å–æ€§èƒ½ç»Ÿè®¡
            stats = self.get_performance_stats()

            return {
                'status': health['status'],
                'active_downloads': active_downloads,
                'total_downloads': len(self.downloads),
                'disk_writable': health.get('disk_writable', False),
                'memory_mb': health.get('memory_mb', 0),
                'download_stats': stats,
                'version': 'V2 (Optimized)'
            }
        except Exception as e:
            logger.error(f"âŒ è·å–ç³»ç»ŸçŠ¶æ€å¤±è´¥: {e}")
            return {
                'status': 'error',
                'error': str(e),
                'active_downloads': 0,
                'total_downloads': 0
            }

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            if self.executor:
                self.executor.shutdown(wait=True)

            # æ¸…ç†é‡è¯•ç®¡ç†å™¨çš„è¿‡æœŸæ•°æ®
            self.retry_manager.cleanup_old_data()

            # æ¸…ç†è¿‡æœŸçš„ä¸‹è½½è®°å½•ï¼ˆä¿ç•™æœ€è¿‘100ä¸ªï¼‰
            self._cleanup_old_downloads()

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            self._cleanup_temp_files()

            logger.info("âœ… ä¸‹è½½ç®¡ç†å™¨V2æ¸…ç†å®Œæˆ")
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†å¤±è´¥: {e}")

    def _cleanup_old_downloads(self):
        """æ¸…ç†è¿‡æœŸçš„ä¸‹è½½è®°å½•"""
        try:
            with self.lock:
                # ä¿ç•™æœ€è¿‘çš„100ä¸ªä¸‹è½½è®°å½•
                if len(self.downloads) > 100:
                    # æŒ‰æ—¶é—´æ’åºï¼Œä¿ç•™æœ€æ–°çš„100ä¸ª
                    sorted_downloads = sorted(
                        self.downloads.items(),
                        key=lambda x: x[1].get('created_at', datetime.min),
                        reverse=True
                    )

                    # ä¿ç•™å‰100ä¸ªï¼Œåˆ é™¤å…¶ä½™çš„
                    keep_downloads = dict(sorted_downloads[:100])
                    removed_count = len(self.downloads) - len(keep_downloads)
                    self.downloads = keep_downloads

                    if removed_count > 0:
                        logger.info(f"ğŸ§¹ æ¸…ç†äº† {removed_count} ä¸ªè¿‡æœŸä¸‹è½½è®°å½•")
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†ä¸‹è½½è®°å½•å¤±è´¥: {e}")

    def _cleanup_temp_files(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            temp_files_removed = 0

            # æ¸…ç†è¾“å‡ºç›®å½•ä¸­çš„ä¸´æ—¶æ–‡ä»¶
            for temp_dir in [self.output_dir, self.temp_dir]:
                if temp_dir.exists():
                    for file_path in temp_dir.iterdir():
                        if (file_path.is_file() and
                            (file_path.name.endswith('.part') or
                             file_path.name.endswith('.tmp') or
                             file_path.name.startswith('tmp'))):
                            try:
                                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦è¶…è¿‡1å°æ—¶æœªä¿®æ”¹
                                if (datetime.now().timestamp() - file_path.stat().st_mtime) > 3600:
                                    file_path.unlink()
                                    temp_files_removed += 1
                            except Exception as e:
                                logger.debug(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {file_path} - {e}")

            if temp_files_removed > 0:
                logger.info(f"ğŸ§¹ æ¸…ç†äº† {temp_files_removed} ä¸ªä¸´æ—¶æ–‡ä»¶")

        except Exception as e:
            logger.error(f"âŒ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")

    def health_check(self) -> Dict[str, Any]:
        """ç®€åŒ–çš„ç³»ç»Ÿå¥åº·æ£€æŸ¥ - åªæ£€æŸ¥å…³é”®é¡¹ç›®"""
        try:
            # æ£€æŸ¥ç›®å½•çŠ¶æ€
            dir_check = self._check_directories()

            # æ£€æŸ¥å†…å­˜ä½¿ç”¨
            memory_check = self._check_memory_usage()

            # æ£€æŸ¥ä¸‹è½½çŠ¶æ€
            download_check = self._check_downloads_health()

            # è®¡ç®—æ€»ä½“å¥åº·çŠ¶æ€
            all_healthy = (dir_check.get('healthy', True) and
                          memory_check.get('healthy', True) and
                          download_check.get('healthy', True))

            return {
                'status': 'healthy' if all_healthy else 'degraded',
                'timestamp': datetime.now().isoformat(),
                'disk_writable': dir_check.get('output_dir_writable', False),
                'memory_mb': memory_check.get('rss_mb', 0),
                'stuck_downloads': download_check.get('stuck_downloads', 0),
                'active_downloads': download_check.get('active_downloads', 0)
            }

        except Exception as e:
            logger.error(f"âŒ å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            return {
                'status': 'unhealthy',
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }

    def _check_directories(self) -> Dict[str, Any]:
        """æ£€æŸ¥ç›®å½•çŠ¶æ€ - ç®€åŒ–ç‰ˆæœ¬"""
        try:
            output_writable = (self.output_dir.exists() and
                             os.access(self.output_dir, os.W_OK))

            return {
                'healthy': output_writable,
                'output_dir_writable': output_writable
            }
        except Exception as e:
            return {'healthy': False, 'output_dir_writable': False}



    def _check_memory_usage(self) -> Dict[str, Any]:
        """æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µ - ç®€åŒ–ç‰ˆæœ¬"""
        try:
            import psutil
            process = psutil.Process()
            memory_info = process.memory_info()
            rss_mb = memory_info.rss / 1024 / 1024

            return {
                'healthy': rss_mb < 512,  # 512MB é™åˆ¶
                'rss_mb': round(rss_mb, 1)
            }
        except ImportError:
            return {'healthy': True, 'rss_mb': 0}
        except Exception as e:
            return {'healthy': True, 'rss_mb': 0}

    def _check_downloads_health(self) -> Dict[str, Any]:
        """æ£€æŸ¥ä¸‹è½½çŠ¶æ€å¥åº· - ç®€åŒ–ç‰ˆæœ¬"""
        try:
            with self.lock:
                active = len([d for d in self.downloads.values() if d['status'] in ['pending', 'downloading']])
                stuck = len([d for d in self.downloads.values()
                           if d['status'] == 'downloading' and
                           (datetime.now() - d.get('updated_at', datetime.now())).total_seconds() > 300])  # 5åˆ†é’Ÿæ— æ›´æ–°

                return {
                    'healthy': stuck == 0,
                    'active_downloads': active,
                    'stuck_downloads': stuck
                }
        except Exception as e:
            return {'healthy': True, 'active_downloads': 0, 'stuck_downloads': 0}




# å…¨å±€å®ä¾‹
_manager_v2 = None


def get_download_manager_v2() -> DownloadManagerV2:
    """è·å–ä¸‹è½½ç®¡ç†å™¨V2å®ä¾‹"""
    global _manager_v2
    if _manager_v2 is None:
        _manager_v2 = DownloadManagerV2()
    return _manager_v2


# å‘åå…¼å®¹çš„åˆ«å
def get_download_manager() -> DownloadManagerV2:
    """å‘åå…¼å®¹çš„è·å–ä¸‹è½½ç®¡ç†å™¨æ–¹æ³•"""
    return get_download_manager_v2()
