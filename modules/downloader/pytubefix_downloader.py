# -*- coding: utf-8 -*-
"""
PyTubeFixä¸‹è½½å™¨ - åŸºäºPyTubeFixçš„YouTubeä¸‹è½½å¼•æ“
"""

import logging
import asyncio
import threading
import time
import os
from typing import Optional, Dict, Any, List
from urllib.parse import urlparse, parse_qs

logger = logging.getLogger(__name__)


class PyTubeFixDownloader:
    """PyTubeFixä¸‹è½½å™¨ - ä¼˜åŒ–ç‰ˆï¼Œæ”¯æŒYouTubeå¯¹è±¡ç¼“å­˜"""

    def __init__(self, proxy: Optional[str] = None):
        # ä½¿ç”¨ç»Ÿä¸€çš„ä»£ç†è½¬æ¢å™¨
        from core.proxy_converter import ProxyConverter
        if proxy:
            # å¦‚æœä¼ å…¥äº†å…·ä½“çš„ä»£ç†URLï¼Œç›´æ¥ä½¿ç”¨
            self.proxy = proxy
        else:
            # ä»æ•°æ®åº“è·å–ä»£ç†é…ç½®å¹¶è½¬æ¢ä¸ºPyTubeFixæ ¼å¼
            self.proxy = ProxyConverter.get_pytubefix_proxy("PyTubeFix")

        self.name = "PyTubeFix"
        self.version = self._get_version()

        # ä½¿ç”¨ç»Ÿä¸€çš„PO Tokenç®¡ç†å™¨
        from core.po_token_manager import get_po_token_manager
        self.po_token_manager = get_po_token_manager()

        # YouTubeå¯¹è±¡ç¼“å­˜ - é¿å…é‡å¤åˆ›å»º
        self._youtube_cache = {}  # URL -> (YouTubeå¯¹è±¡, åˆ›å»ºæ—¶é—´)
        self._cache_timeout = 300  # ç¼“å­˜5åˆ†é’Ÿ

        # è¿›åº¦å›è°ƒå‡½æ•°
        self._progress_callback = None
        self._download_id = None

    def _get_version(self) -> str:
        """è·å–PyTubeFixç‰ˆæœ¬"""
        try:
            import pytubefix
            return getattr(pytubefix, '__version__', 'unknown')
        except ImportError:
            return 'not_installed'

    def _get_or_create_youtube(self, url: str, force_refresh: bool = False) -> Optional[object]:
        """è·å–æˆ–åˆ›å»ºYouTubeå¯¹è±¡ï¼Œæ”¯æŒç¼“å­˜"""
        try:
            import time
            from pytubefix import YouTube

            current_time = time.time()

            # æ£€æŸ¥ç¼“å­˜
            if not force_refresh and url in self._youtube_cache:
                yt_obj, created_time = self._youtube_cache[url]

                # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
                if current_time - created_time < self._cache_timeout:
                    logger.debug(f"ğŸ”„ ä½¿ç”¨ç¼“å­˜çš„YouTubeå¯¹è±¡: {url[:50]}...")
                    return yt_obj
                else:
                    logger.debug(f"â° YouTubeå¯¹è±¡ç¼“å­˜å·²è¿‡æœŸï¼Œé‡æ–°åˆ›å»º")
                    del self._youtube_cache[url]

            # åˆ›å»ºæ–°çš„YouTubeå¯¹è±¡
            logger.info(f"ğŸ†• åˆ›å»ºæ–°çš„YouTubeå¯¹è±¡: {url[:50]}...")

            # æ„å»ºé…ç½®å‚æ•°
            yt_kwargs = {}

            # ä»£ç†é…ç½®
            if self.proxy:
                proxy_config = self._configure_proxy_for_pytubefix(self.proxy)
                if proxy_config:
                    yt_kwargs.update(proxy_config)
                    logger.debug(f"âœ… ä½¿ç”¨ä»£ç†: {self.proxy}")

            # åº”ç”¨PO Tokené…ç½®
            yt_kwargs = self.po_token_manager.apply_to_pytubefix_kwargs(yt_kwargs, "PyTubeFix-Cached")

            # æ ‡å‡†è®¤è¯æ¨¡å¼
            yt_kwargs.update({
                'use_oauth': False,
                'allow_oauth_cache': False,
            })

            # æ™ºèƒ½å®¢æˆ·ç«¯é€‰æ‹©
            import os
            is_container = (
                os.environ.get('CONTAINER_ENV') == '1' or
                os.environ.get('DOCKER_CONTAINER') == '1' or
                os.environ.get('VPS_ENV') == '1'
            )

            client_type, client_reason = self._select_optimal_client(is_container)
            logger.debug(f"ğŸ¯ é€‰æ‹©å®¢æˆ·ç«¯: {client_type} - {client_reason}")

            # åˆ›å»ºYouTubeå¯¹è±¡
            yt = YouTube(url, client_type, **yt_kwargs)

            # ç¼“å­˜å¯¹è±¡
            self._youtube_cache[url] = (yt, current_time)
            logger.info(f"âœ… YouTubeå¯¹è±¡åˆ›å»ºå¹¶ç¼“å­˜æˆåŠŸ")

            return yt

        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºYouTubeå¯¹è±¡å¤±è´¥: {e}")
            return None

    def _clear_cache(self):
        """æ¸…ç†ç¼“å­˜"""
        self._youtube_cache.clear()
        logger.debug("ğŸ§¹ YouTubeå¯¹è±¡ç¼“å­˜å·²æ¸…ç†")

    def _get_cache_info(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ä¿¡æ¯"""
        import time
        current_time = time.time()

        cache_info = {
            'total_cached': len(self._youtube_cache),
            'cache_timeout': self._cache_timeout,
            'cached_urls': []
        }

        for url, (yt_obj, created_time) in self._youtube_cache.items():
            age = current_time - created_time
            cache_info['cached_urls'].append({
                'url': url[:50] + '...' if len(url) > 50 else url,
                'age_seconds': int(age),
                'expired': age > self._cache_timeout
            })

        return cache_info



    def _check_nodejs_available(self) -> bool:
        """æ£€æŸ¥nodejsæ˜¯å¦å¯ç”¨"""
        try:
            import subprocess
            result = subprocess.run(['node', '--version'],
                                  capture_output=True,
                                  text=True,
                                  timeout=5)
            if result.returncode == 0:
                version = result.stdout.strip()
                logger.debug(f"âœ… æ£€æµ‹åˆ°nodejs: {version}")
                return True
            else:
                logger.debug("âŒ nodejsä¸å¯ç”¨")
                return False
        except (subprocess.TimeoutExpired, FileNotFoundError, Exception) as e:
            logger.debug(f"âŒ nodejsæ£€æµ‹å¤±è´¥: {e}")
            return False

    def _select_optimal_client(self, is_container: bool) -> tuple[str, str]:
        """æ™ºèƒ½é€‰æ‹©æœ€ä¼˜å®¢æˆ·ç«¯"""
        try:
            # ä½¿ç”¨ç»Ÿä¸€çš„å®¢æˆ·ç«¯é€‰æ‹©é€»è¾‘
            use_web, reason = self.po_token_manager.should_use_web_client(is_container)

            if use_web:
                return 'WEB', reason
            else:
                return 'ANDROID', reason

        except Exception as e:
            logger.warning(f"âš ï¸ å®¢æˆ·ç«¯é€‰æ‹©å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤: {e}")
            return 'ANDROID', 'é»˜è®¤ç¨³å®šæ¨¡å¼'
    
    def _extract_video_id(self, url: str) -> Optional[str]:
        """ä»URLä¸­æå–è§†é¢‘ID"""
        try:
            parsed_url = urlparse(url)
            
            if 'youtube.com' in parsed_url.netloc:
                if '/watch' in parsed_url.path:
                    query_params = parse_qs(parsed_url.query)
                    return query_params.get('v', [None])[0]
                elif '/embed/' in parsed_url.path:
                    return parsed_url.path.split('/embed/')[-1].split('?')[0]
                elif '/v/' in parsed_url.path:
                    return parsed_url.path.split('/v/')[-1].split('?')[0]
            elif 'youtu.be' in parsed_url.netloc:
                return parsed_url.path.lstrip('/')
                
            return None
        except Exception as e:
            logger.error(f"âŒ æå–è§†é¢‘IDå¤±è´¥: {e}")
            return None

    def _is_youtube_url(self, url: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºYouTube URL"""
        try:
            parsed_url = urlparse(url.lower())

            # YouTube å®˜æ–¹åŸŸååˆ—è¡¨
            youtube_domains = [
                'youtube.com',
                'www.youtube.com',
                'm.youtube.com',
                'music.youtube.com',
                'youtu.be',
                'youtube-nocookie.com',
                'www.youtube-nocookie.com'
            ]

            is_youtube = parsed_url.netloc in youtube_domains

            if is_youtube:
                logger.debug(f"âœ… PyTubeFixæ£€æµ‹åˆ°YouTube URL: {parsed_url.netloc}")
            else:
                logger.debug(f"ğŸŒ PyTubeFixæ£€æµ‹åˆ°éYouTube URL: {parsed_url.netloc}")

            return is_youtube

        except Exception as e:
            logger.error(f"âŒ PyTubeFix URLæ£€æµ‹å¤±è´¥: {e}")
            # å¦‚æœæ£€æµ‹å¤±è´¥ï¼Œä¿å®ˆåœ°å‡è®¾ä¸æ˜¯YouTube
            return False
    
    async def extract_info(self, url: str, quality: str = "720") -> Optional[Dict[str, Any]]:
        """æå–è§†é¢‘ä¿¡æ¯"""
        try:
            logger.info(f"ğŸ”§ PyTubeFixå¼€å§‹æå–: {url}")

            # é¦–å…ˆæ£€æŸ¥æ˜¯å¦ä¸ºYouTube URL
            if not self._is_youtube_url(url):
                logger.warning(f"âš ï¸ PyTubeFixåªæ”¯æŒYouTubeï¼Œè·³è¿‡: {url}")
                return {
                    'error': 'unsupported_site',
                    'message': 'PyTubeFixåªæ”¯æŒYouTubeç½‘ç«™'
                }

            # æ£€æŸ¥PyTubeFixæ˜¯å¦å¯ç”¨
            try:
                from pytubefix import YouTube
            except ImportError:
                logger.error("âŒ PyTubeFixæœªå®‰è£…")
                return {
                    'error': 'pytubefix_not_installed',
                    'message': 'PyTubeFixæœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…PyTubeFix'
                }

            # æå–è§†é¢‘ID
            video_id = self._extract_video_id(url)
            if not video_id:
                logger.error(f"âŒ æ— æ³•æå–è§†é¢‘ID: {url}")
                return {
                    'error': 'invalid_url',
                    'message': 'æ— æ•ˆçš„YouTube URL'
                }
            
            # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥æ“ä½œ
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(None, self._extract_sync, url, quality)
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ PyTubeFixæå–å¼‚å¸¸: {e}")
            return {
                'error': 'extraction_failed',
                'message': f'PyTubeFixæå–å¤±è´¥: {str(e)}'
            }
    
    def _extract_sync(self, url: str, quality: str) -> Dict[str, Any]:
        """åŒæ­¥æå–è§†é¢‘ä¿¡æ¯ï¼ˆä¼˜åŒ–ç‰ˆï¼Œä½¿ç”¨ç¼“å­˜ï¼‰"""
        try:
            # ä½¿ç”¨ç¼“å­˜çš„YouTubeå¯¹è±¡
            yt = self._get_or_create_youtube(url)

            if not yt:
                return {
                    'error': 'creation_failed',
                    'message': 'PyTubeFix YouTubeå¯¹è±¡åˆ›å»ºå¤±è´¥'
                }
            
            # è·å–åŸºæœ¬ä¿¡æ¯
            basic_info = {
                'title': yt.title,
                'duration': yt.length,
                'description': yt.description,
                'uploader': yt.author,
                'upload_date': yt.publish_date.strftime('%Y%m%d') if yt.publish_date else None,
                'view_count': yt.views,
                'thumbnail': yt.thumbnail_url,
                'video_id': yt.video_id,
                'extractor': 'pytubefix',
                'webpage_url': url
            }
            
            # è·å–æ ¼å¼ä¿¡æ¯
            formats = self._extract_formats(yt)
            
            result = {
                **basic_info,
                'formats': formats,
                'format_count': len(formats)
            }
            
            logger.info(f"âœ… PyTubeFixæå–æˆåŠŸ: {basic_info['title']} ({len(formats)}ä¸ªæ ¼å¼)")
            return result
            
        except Exception as e:
            logger.error(f"âŒ PyTubeFixåŒæ­¥æå–å¤±è´¥: {e}")
            return {
                'error': 'sync_extraction_failed',
                'message': f'PyTubeFixåŒæ­¥æå–å¤±è´¥: {str(e)}'
            }

    def _configure_proxy_for_pytubefix(self, proxy_url: str) -> Dict[str, Any]:
        """ä¸ºPyTubeFixé…ç½®ä»£ç† - ä½¿ç”¨ç»Ÿä¸€çš„ä»£ç†è½¬æ¢å™¨"""
        try:
            if not proxy_url:
                return {}

            # ä½¿ç”¨ç»Ÿä¸€çš„ä»£ç†è½¬æ¢å™¨å¤„ç†SOCKS5
            from core.proxy_converter import ProxyConverter
            return ProxyConverter.get_pytubefix_socks5_config(proxy_url, "PyTubeFix")

        except Exception as e:
            logger.error(f"âŒ PyTubeFixä»£ç†é…ç½®å¤±è´¥: {e}")
            return {}
    
    def _extract_formats(self, yt) -> List[Dict[str, Any]]:
        """æå–æ ¼å¼ä¿¡æ¯"""
        formats = []
        
        try:
            # è·å–æ‰€æœ‰æµ
            streams = yt.streams
            
            for stream in streams:
                try:
                    format_info = {
                        'format_id': f"pytubefix-{stream.itag}",
                        'url': stream.url,
                        'ext': stream.mime_type.split('/')[-1] if stream.mime_type else 'mp4',
                        'quality': stream.resolution or 'audio',
                        'qualityLabel': stream.resolution or 'audio only',
                        'height': int(stream.resolution.replace('p', '')) if stream.resolution else None,
                        'fps': getattr(stream, 'fps', None),  # å®‰å…¨è·å–fpså±æ€§
                        'vcodec': getattr(stream, 'video_codec', None),  # å®‰å…¨è·å–è§†é¢‘ç¼–ç 
                        'acodec': getattr(stream, 'audio_codec', None),  # å®‰å…¨è·å–éŸ³é¢‘ç¼–ç 
                        'filesize': getattr(stream, 'filesize', None),  # å®‰å…¨è·å–æ–‡ä»¶å¤§å°
                        'bitrate': getattr(stream, 'bitrate', None),  # å®‰å…¨è·å–æ¯”ç‰¹ç‡
                        'mime_type': getattr(stream, 'mime_type', None),  # å®‰å…¨è·å–MIMEç±»å‹
                        'type': getattr(stream, 'type', 'unknown'),  # å®‰å…¨è·å–ç±»å‹
                        'progressive': getattr(stream, 'is_progressive', False),  # å®‰å…¨è·å–progressiveçŠ¶æ€
                        'adaptive': getattr(stream, 'is_adaptive', False),  # å®‰å…¨è·å–adaptiveçŠ¶æ€
                        'itag': getattr(stream, 'itag', None)  # å®‰å…¨è·å–itag
                    }

                    formats.append(format_info)

                except Exception as stream_error:
                    # å•ä¸ªæµå¤„ç†å¤±è´¥æ—¶ï¼Œè®°å½•é”™è¯¯ä½†ç»§ç»­å¤„ç†å…¶ä»–æµ
                    logger.warning(f"âš ï¸ è·³è¿‡æœ‰é—®é¢˜çš„æµ {getattr(stream, 'itag', 'unknown')}: {stream_error}")
                    continue
            
            # æŒ‰è´¨é‡æ’åº
            formats.sort(key=lambda x: (
                x.get('height', 0) if x.get('height') else 0,
                x.get('bitrate', 0) if x.get('bitrate') else 0
            ), reverse=True)
            
            logger.debug(f"ğŸ“Š æå–åˆ° {len(formats)} ä¸ªæ ¼å¼")
            return formats
            
        except Exception as e:
            logger.error(f"âŒ æ ¼å¼æå–å¤±è´¥: {e}")
            return []
    
    async def download(self, url: str, output_path: str, quality: str = "720") -> Dict[str, Any]:
        """ä¸‹è½½è§†é¢‘"""
        try:
            logger.info(f"ğŸ“¥ PyTubeFixå¼€å§‹ä¸‹è½½: {url}")

            # é¦–å…ˆæ£€æŸ¥æ˜¯å¦ä¸ºYouTube URL
            if not self._is_youtube_url(url):
                logger.warning(f"âš ï¸ PyTubeFixåªæ”¯æŒYouTubeï¼Œè·³è¿‡ä¸‹è½½: {url}")
                return {
                    'error': 'unsupported_site',
                    'message': 'PyTubeFixåªæ”¯æŒYouTubeç½‘ç«™'
                }

            # å…ˆæå–ä¿¡æ¯
            info = await self.extract_info(url, quality)
            if not info or info.get('error'):
                return info or {'error': 'extraction_failed', 'message': 'ä¿¡æ¯æå–å¤±è´¥'}
            
            # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œä¸‹è½½
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(None, self._download_sync, url, output_path, quality)
            
            return result

        except Exception as e:
            logger.error(f"âŒ PyTubeFixä¸‹è½½å¼‚å¸¸: {e}")
            return {
                'error': 'download_failed',
                'message': f'PyTubeFixä¸‹è½½å¤±è´¥: {str(e)}'
            }

    async def download_with_cached_info(self, url: str, output_path: str, quality: str = "720", video_info: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """ä½¿ç”¨å·²ç¼“å­˜ä¿¡æ¯è¿›è¡Œä¸‹è½½ï¼Œé¿å…é‡å¤æå–"""
        try:
            logger.info(f"ğŸ“¥ PyTubeFixå¼€å§‹ç¼“å­˜ä¸‹è½½: {url}")

            # é¦–å…ˆæ£€æŸ¥æ˜¯å¦ä¸ºYouTube URL
            if not self._is_youtube_url(url):
                logger.warning(f"âš ï¸ PyTubeFixåªæ”¯æŒYouTubeï¼Œè·³è¿‡ä¸‹è½½: {url}")
                return {
                    'error': 'unsupported_site',
                    'message': 'PyTubeFixåªæ”¯æŒYouTubeç½‘ç«™'
                }

            # å¦‚æœæ²¡æœ‰ä¼ å…¥video_infoï¼Œå…ˆæå–ä¿¡æ¯
            if not video_info:
                logger.info("ğŸ“‹ æœªæä¾›è§†é¢‘ä¿¡æ¯ï¼Œå…ˆè¿›è¡Œæå–")
                info = await self.extract_info(url, quality)
                if not info or info.get('error'):
                    return info or {'error': 'extraction_failed', 'message': 'ä¿¡æ¯æå–å¤±è´¥'}
                video_info = info
            else:
                logger.info("âœ… ä½¿ç”¨å·²æä¾›çš„è§†é¢‘ä¿¡æ¯ï¼Œè·³è¿‡é‡å¤æå–")

            # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œä¸‹è½½ï¼ˆå¤ç”¨ç¼“å­˜çš„YouTubeå¯¹è±¡ï¼‰
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(None, self._download_sync, url, output_path, quality)

            # åˆå¹¶è§†é¢‘ä¿¡æ¯åˆ°ç»“æœä¸­
            if result.get('success') and video_info:
                result.update({
                    'video_info': video_info,
                    'cached_download': True
                })

            return result

        except Exception as e:
            logger.error(f"âŒ PyTubeFixç¼“å­˜ä¸‹è½½å¼‚å¸¸: {e}")
            return {
                'error': 'cached_download_failed',
                'message': f'PyTubeFixç¼“å­˜ä¸‹è½½å¤±è´¥: {str(e)}'
            }
    
    def _download_sync(self, url: str, output_path: str, quality: str) -> Dict[str, Any]:
        """åŒæ­¥ä¸‹è½½è§†é¢‘ï¼ˆä¼˜åŒ–ç‰ˆï¼Œå¤ç”¨ç¼“å­˜çš„YouTubeå¯¹è±¡ï¼‰"""
        try:
            import os

            # å¤ç”¨ç¼“å­˜çš„YouTubeå¯¹è±¡ï¼Œé¿å…é‡å¤åˆ›å»º
            yt = self._get_or_create_youtube(url)

            if not yt:
                return {
                    'error': 'youtube_object_failed',
                    'message': 'æ— æ³•è·å–YouTubeå¯¹è±¡'
                }

            logger.info(f"ğŸ”„ å¤ç”¨YouTubeå¯¹è±¡è¿›è¡Œä¸‹è½½")
            
            # æ™ºèƒ½æµé€‰æ‹©ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
            stream = self._select_optimal_stream(yt, quality)

            if not stream:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æµï¼Œå°è¯•é™çº§ç­–ç•¥
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°è´¨é‡ {quality} çš„æµï¼Œå°è¯•é™çº§ç­–ç•¥")
                stream = self._fallback_stream_selection(yt, quality)
            
            if not stream:
                return {
                    'error': 'no_stream_found',
                    'message': 'æœªæ‰¾åˆ°å¯ç”¨çš„è§†é¢‘æµ'
                }
            
            # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
            os.makedirs(output_path, exist_ok=True)

            # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆå¹¶Adaptive streams
            if hasattr(stream, '_needs_merge') and stream._needs_merge:
                # ä¸‹è½½Adaptiveæ ¼å¼ï¼ˆéœ€è¦åˆå¹¶ï¼‰
                downloaded_file = self._download_adaptive_stream(yt, stream, output_path)
            else:
                # ä¸‹è½½Progressiveæ ¼å¼ï¼ˆå•ä¸€æ–‡ä»¶ï¼‰- å¸¦è¿›åº¦ç›‘æ§
                downloaded_file = self._download_with_progress(stream, output_path)

            if not downloaded_file:
                return {
                    'error': 'download_failed',
                    'message': 'æ–‡ä»¶ä¸‹è½½å¤±è´¥'
                }

            result = {
                'success': True,
                'title': yt.title,
                'filename': os.path.basename(downloaded_file),
                'file_path': downloaded_file,  # ä¿®å¤ï¼šä½¿ç”¨ç»Ÿä¸€çš„å­—æ®µå
                'filepath': downloaded_file,   # ä¿ç•™å‘åå…¼å®¹
                'file_size': os.path.getsize(downloaded_file) if os.path.exists(downloaded_file) else 0,  # ä¿®å¤ï¼šä½¿ç”¨ç»Ÿä¸€çš„å­—æ®µå
                'filesize': os.path.getsize(downloaded_file) if os.path.exists(downloaded_file) else 0,   # ä¿ç•™å‘åå…¼å®¹
                'quality': stream.resolution or 'audio',
                'format': stream.mime_type,
                'extractor': 'pytubefix'
            }
            
            logger.info(f"âœ… PyTubeFixä¸‹è½½æˆåŠŸ: {result['filename']}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ PyTubeFixåŒæ­¥ä¸‹è½½å¤±è´¥: {e}")
            return {
                'error': 'sync_download_failed',
                'message': f'PyTubeFixåŒæ­¥ä¸‹è½½å¤±è´¥: {str(e)}'
            }
    
    def _select_optimal_stream(self, yt, quality: str):
        """æ™ºèƒ½æµé€‰æ‹© - æ”¯æŒ4Kå’Œè‡ªåŠ¨é™çº§"""
        try:
            # é¦–å…ˆå°è¯•è·å–æŒ‡å®šè´¨é‡çš„æµï¼ˆåŒ…æ‹¬adaptive streamsï¼‰
            stream = self._get_stream_by_quality(yt, quality)
            if stream:
                return stream

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨é™çº§ç­–ç•¥
            logger.warning(f"âš ï¸ æœªæ‰¾åˆ°è´¨é‡ {quality} çš„æµï¼Œå¼€å§‹é™çº§ç­–ç•¥")
            return self._fallback_stream_selection(yt, quality)

        except Exception as e:
            logger.error(f"âŒ æµé€‰æ‹©å¤±è´¥: {e}")
            return None

    def _get_stream_by_quality(self, yt, quality: str):
        """æ ¹æ®è´¨é‡è·å–æœ€ä½³æµ"""
        try:
            # å®šä¹‰è´¨é‡åˆ°åˆ†è¾¨ç‡çš„æ˜ å°„
            quality_resolution_map = {
                '4k': '2160p',
                '2k': '1440p',
                'high': '1080p',
                'medium': '720p',
                'low': '480p'
            }

            # è·å–ç›®æ ‡åˆ†è¾¨ç‡
            target_res = quality_resolution_map.get(quality, quality)

            # å¦‚æœæ˜¯æ•°å­—æ ¼å¼ï¼Œæ·»åŠ p
            if target_res.isdigit():
                target_res = f"{target_res}p"

            logger.info(f"ğŸ¯ å¯»æ‰¾è´¨é‡: {quality} -> {target_res}")

            # ç‰¹æ®Šå¤„ç†
            if quality == 'best':
                return yt.streams.get_highest_resolution()
            elif quality == 'worst':
                return yt.streams.get_lowest_resolution()
            elif quality == 'audio':
                return yt.streams.get_audio_only()

            # å¯¹äºé«˜åˆ†è¾¨ç‡ï¼ˆ1080p+ï¼‰ï¼Œç›´æ¥é™çº§åˆ°Progressiveæ ¼å¼ä»¥é¿å…ç½‘ç»œé—®é¢˜
            if target_res in ['2160p', '1440p', '1080p']:
                logger.info(f"ğŸ”„ é«˜åˆ†è¾¨ç‡{target_res}é™çº§åˆ°Progressiveæ ¼å¼ä»¥æé«˜ç¨³å®šæ€§")
                fallback_progressive = self._get_progressive_fallback(yt, target_res)
                if fallback_progressive:
                    logger.info(f"âœ… æ‰¾åˆ°Progressiveé™çº§æµ: {fallback_progressive.resolution}")
                    return fallback_progressive

            # ä¼˜å…ˆå°è¯•Progressiveæ ¼å¼ï¼ˆé¢„åˆå¹¶ï¼Œæ›´ç¨³å®šï¼‰
            progressive_stream = yt.streams.filter(progressive=True, res=target_res).first()
            if progressive_stream:
                logger.info(f"âœ… æ‰¾åˆ°Progressiveæµ: {target_res}")
                return progressive_stream

            # å¦‚æœæ²¡æœ‰Progressiveæ ¼å¼ï¼Œå°è¯•ç¨ä½åˆ†è¾¨ç‡çš„Progressiveæ ¼å¼
            if target_res in ['720p', '480p', '360p']:
                fallback_progressive = self._get_progressive_fallback(yt, target_res)
                if fallback_progressive:
                    logger.info(f"âœ… æ‰¾åˆ°Progressiveé™çº§æµ: {fallback_progressive.resolution}")
                    return fallback_progressive

            # æœ€åæ‰è€ƒè™‘Adaptiveæ ¼å¼ï¼ˆç½‘ç»œè¦æ±‚é«˜ï¼Œå®¹æ˜“å¤±è´¥ï¼‰
            adaptive_video = yt.streams.filter(adaptive=True, type='video', res=target_res).first()
            if adaptive_video:
                logger.warning(f"âš ï¸ ä½¿ç”¨Adaptiveè§†é¢‘æµ: {target_res}ï¼Œç½‘ç»œè¦æ±‚è¾ƒé«˜")
                # æ ‡è®°è¿™æ˜¯ä¸€ä¸ªéœ€è¦åˆå¹¶çš„æµ
                adaptive_video._needs_merge = True
                return adaptive_video

            # å°è¯•ä¸æŒ‡å®šåˆ†è¾¨ç‡çš„åŒ¹é…
            if target_res.endswith('p'):
                fallback_stream = yt.streams.filter(res=target_res).first()
                if fallback_stream:
                    logger.info(f"âœ… æ‰¾åˆ°å¤‡é€‰æµ: {target_res}")
                    return fallback_stream

            return None

        except Exception as e:
            logger.error(f"âŒ è·å–è´¨é‡æµå¤±è´¥: {e}")
            return None

    def _get_progressive_fallback(self, yt, target_res: str):
        """è·å–Progressiveæ ¼å¼çš„é™çº§æµï¼ˆä¼˜åŒ–ç‰ˆï¼Œæ›´å¤šé™çº§é€‰é¡¹ï¼‰"""
        try:
            # Progressiveé™çº§é¡ºåºï¼ˆåŒ…å«æ›´å¤šé€‰é¡¹ï¼Œä¼˜å…ˆç¨³å®šæ€§ï¼‰
            progressive_fallback = {
                '2160p': ['720p', '480p', '360p'],  # 4Kç›´æ¥é™åˆ°720p
                '1440p': ['720p', '480p', '360p'],  # 2Kç›´æ¥é™åˆ°720p
                '1080p': ['720p', '480p', '360p'],  # 1080pç›´æ¥é™åˆ°720p
                '720p': ['480p', '360p'],
                '480p': ['360p'],
                '360p': []
            }

            fallback_list = progressive_fallback.get(target_res, ['720p', '480p', '360p'])

            for fallback_res in fallback_list:
                progressive_stream = yt.streams.filter(progressive=True, res=fallback_res).first()
                if progressive_stream:
                    logger.info(f"âœ… Progressiveé™çº§: {target_res} -> {fallback_res}")
                    return progressive_stream

            # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•è·å–ä»»ä½•å¯ç”¨çš„Progressiveæµ
            any_progressive = yt.streams.filter(progressive=True).order_by('resolution').desc().first()
            if any_progressive:
                logger.info(f"âœ… ä½¿ç”¨æœ€é«˜å¯ç”¨Progressiveæµ: {any_progressive.resolution}")
                return any_progressive

            return None

        except Exception as e:
            logger.error(f"âŒ Progressiveé™çº§å¤±è´¥: {e}")
            return None

    def _fallback_stream_selection(self, yt, original_quality: str):
        """é™çº§æµé€‰æ‹©ç­–ç•¥ - æ”¯æŒ4Ké™çº§"""
        try:
            # æ ¹æ®åŸå§‹è´¨é‡ç¡®å®šé™çº§é¡ºåºï¼ˆä¼˜åŒ–ï¼šå‡å°‘é™çº§çº§åˆ«ï¼‰
            if original_quality in ['4k', '2160p']:
                fallback_order = ['2160p', '1080p', '720p']  # å‡å°‘åˆ°3ä¸ªçº§åˆ«
            elif original_quality in ['2k', '1440p']:
                fallback_order = ['1440p', '1080p', '720p']  # å‡å°‘åˆ°3ä¸ªçº§åˆ«
            elif original_quality in ['high', '1080p']:
                fallback_order = ['1080p', '720p', '480p']   # å‡å°‘åˆ°3ä¸ªçº§åˆ«
            elif original_quality in ['medium', '720p']:
                fallback_order = ['720p', '480p', '360p']    # ä¿æŒ3ä¸ªçº§åˆ«
            elif original_quality in ['low', '480p']:
                fallback_order = ['480p', '360p']            # å‡å°‘åˆ°2ä¸ªçº§åˆ«
            else:
                # é»˜è®¤é™çº§é¡ºåºï¼ˆå‡å°‘çº§åˆ«ï¼‰
                fallback_order = ['1080p', '720p', '480p']   # å‡å°‘åˆ°3ä¸ªçº§åˆ«

            logger.info(f"ğŸ”„ å¼€å§‹é™çº§ç­–ç•¥ï¼ŒåŸå§‹è´¨é‡: {original_quality}")
            logger.info(f"ğŸ”„ é™çº§é¡ºåº: {' -> '.join(fallback_order)}")

            for fallback_quality in fallback_order:
                # å°è¯•è·å–è¯¥è´¨é‡çš„æµ
                stream = self._get_stream_by_quality(yt, fallback_quality)
                if stream:
                    logger.info(f"âœ… é™çº§æˆåŠŸ: {original_quality} -> {fallback_quality}")
                    return stream

            # æœ€åå°è¯•è·å–ä»»ä½•å¯ç”¨çš„æœ€é«˜è´¨é‡è§†é¢‘æµ
            stream = yt.streams.get_highest_resolution()
            if stream:
                logger.info(f"âœ… ä½¿ç”¨æœ€é«˜å¯ç”¨è´¨é‡: {getattr(stream, 'resolution', 'unknown')}")
                return stream

            # å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œå°è¯•éŸ³é¢‘æµ
            stream = yt.streams.get_audio_only()
            if stream:
                logger.info("âœ… æœ€ç»ˆé™çº§åˆ°éŸ³é¢‘æµ")
                return stream

            return None

        except Exception as e:
            logger.error(f"âŒ é™çº§ç­–ç•¥å¤±è´¥: {e}")
            return None

    def _download_adaptive_stream(self, yt, video_stream, output_path: str) -> str:
        """ä¸‹è½½Adaptiveæ ¼å¼å¹¶åˆå¹¶"""
        try:
            import tempfile
            import uuid
            import os
            from pathlib import Path

            logger.info(f"ğŸ”§ å¼€å§‹ä¸‹è½½Adaptiveæ ¼å¼: {video_stream.resolution}")

            # è·å–æœ€ä½³éŸ³é¢‘æµ
            audio_stream = yt.streams.filter(only_audio=True, file_extension='mp4').order_by('abr').desc().first()
            if not audio_stream:
                # å¦‚æœæ²¡æœ‰mp4éŸ³é¢‘ï¼Œå°è¯•å…¶ä»–æ ¼å¼
                audio_stream = yt.streams.filter(only_audio=True).order_by('abr').desc().first()

            if not audio_stream:
                logger.error("âŒ æœªæ‰¾åˆ°éŸ³é¢‘æµ")
                return None

            logger.info(f"ğŸµ é€‰æ‹©éŸ³é¢‘æµ: {audio_stream.abr} {audio_stream.mime_type}")

            # åˆ›å»ºä¸´æ—¶ç›®å½•
            temp_dir = tempfile.mkdtemp(prefix='pytubefix_')
            temp_video_path = None
            temp_audio_path = None

            try:
                # ä¸‹è½½è§†é¢‘æµ
                logger.info("ğŸ“¹ ä¸‹è½½è§†é¢‘æµ...")
                temp_video_path = video_stream.download(output_path=temp_dir, filename_prefix='video_')

                # ä¸‹è½½éŸ³é¢‘æµ
                logger.info("ğŸµ ä¸‹è½½éŸ³é¢‘æµ...")
                temp_audio_path = audio_stream.download(output_path=temp_dir, filename_prefix='audio_')

                # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
                safe_title = self._sanitize_filename(yt.title)
                output_filename = f"{safe_title}.mp4"
                final_output_path = os.path.join(output_path, output_filename)

                # ä½¿ç”¨FFmpegåˆå¹¶
                logger.info("ğŸ”§ ä½¿ç”¨FFmpegåˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘...")
                success = self._merge_video_audio(temp_video_path, temp_audio_path, final_output_path)

                if success and os.path.exists(final_output_path):
                    logger.info(f"âœ… Adaptiveæ ¼å¼åˆå¹¶æˆåŠŸ: {output_filename}")
                    return final_output_path
                else:
                    logger.error("âŒ FFmpegåˆå¹¶å¤±è´¥")
                    return None

            finally:
                # å¢å¼ºçš„ä¸´æ—¶æ–‡ä»¶æ¸…ç†
                self._cleanup_temp_files(temp_dir, temp_video_path, temp_audio_path)

        except Exception as e:
            logger.error(f"âŒ Adaptiveä¸‹è½½å¤±è´¥: {e}")
            return None

    def _download_stream_with_retry(self, stream, output_dir: str, filename_prefix: str, max_retries: int = 3) -> Optional[str]:
        """å¸¦é‡è¯•æœºåˆ¶çš„æµä¸‹è½½"""
        import time

        for attempt in range(max_retries):
            try:
                logger.info(f"ğŸ”„ å°è¯•ä¸‹è½½æµ (ç¬¬ {attempt + 1}/{max_retries} æ¬¡): {filename_prefix}")

                # å°è¯•ä¸‹è½½
                result = stream.download(output_path=output_dir, filename_prefix=filename_prefix)

                if result:
                    logger.info(f"âœ… æµä¸‹è½½æˆåŠŸ: {filename_prefix}")
                    return result
                else:
                    logger.warning(f"âš ï¸ æµä¸‹è½½è¿”å›ç©ºç»“æœ: {filename_prefix}")

            except Exception as e:
                error_msg = str(e)
                logger.warning(f"âš ï¸ æµä¸‹è½½å¤±è´¥ (ç¬¬ {attempt + 1}/{max_retries} æ¬¡): {error_msg}")

                # æ£€æŸ¥æ˜¯å¦æ˜¯ç½‘ç»œç›¸å…³é”™è¯¯
                if "Maximum reload attempts" in error_msg or "timeout" in error_msg.lower() or "connection" in error_msg.lower():
                    if attempt < max_retries - 1:
                        wait_time = (attempt + 1) * 2  # é€’å¢ç­‰å¾…æ—¶é—´
                        logger.info(f"â±ï¸ ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                        time.sleep(wait_time)
                        continue

                # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•æˆ–éç½‘ç»œé”™è¯¯ï¼Œç›´æ¥æŠ›å‡º
                if attempt == max_retries - 1:
                    logger.error(f"âŒ æµä¸‹è½½æœ€ç»ˆå¤±è´¥: {error_msg}")
                    raise e

        return None

    def _merge_video_audio(self, video_path: str, audio_path: str, output_path: str) -> bool:
        """ä½¿ç”¨FFmpegåˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘"""
        try:
            from modules.downloader.ffmpeg_tools import FFmpegTools

            ffmpeg_tools = FFmpegTools()
            if not ffmpeg_tools.is_available():
                logger.error("âŒ FFmpegä¸å¯ç”¨ï¼Œæ— æ³•åˆå¹¶Adaptiveæ ¼å¼")
                return False

            # ä½¿ç”¨FFmpegåˆå¹¶
            success = ffmpeg_tools.merge_video_audio(
                video_path=video_path,
                audio_path=audio_path,
                output_path=output_path
            )

            return success

        except Exception as e:
            logger.error(f"âŒ FFmpegåˆå¹¶å¼‚å¸¸: {e}")
            return False

    def _sanitize_filename(self, filename: str) -> str:
        """æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤éæ³•å­—ç¬¦"""
        import re
        # ç§»é™¤æˆ–æ›¿æ¢éæ³•å­—ç¬¦
        filename = re.sub(r'[<>:"/\\|?*]', '_', filename)
        # é™åˆ¶é•¿åº¦
        if len(filename) > 100:
            filename = filename[:100]
        return filename.strip()

    def _cleanup_temp_files(self, temp_dir: str = None, *temp_files) -> None:
        """å¢å¼ºçš„ä¸´æ—¶æ–‡ä»¶æ¸…ç†ï¼Œç¡®ä¿èµ„æºé‡Šæ”¾"""
        import shutil
        import time
        import os

        cleanup_errors = []

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        for temp_file in temp_files:
            if temp_file and os.path.exists(temp_file):
                try:
                    # å°è¯•å¤šæ¬¡åˆ é™¤ï¼ˆWindowsæ–‡ä»¶é”å®šé—®é¢˜ï¼‰
                    for attempt in range(3):
                        try:
                            os.remove(temp_file)
                            logger.debug(f"âœ… æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {temp_file}")
                            break
                        except PermissionError:
                            if attempt < 2:
                                time.sleep(0.1)  # ç­‰å¾…æ–‡ä»¶å¥æŸ„é‡Šæ”¾
                                continue
                            raise
                except Exception as e:
                    cleanup_errors.append(f"æ–‡ä»¶ {temp_file}: {e}")
                    logger.warning(f"âš ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {temp_file} - {e}")

        # æ¸…ç†ä¸´æ—¶ç›®å½•
        if temp_dir and os.path.exists(temp_dir):
            try:
                # å°è¯•åˆ é™¤ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶
                for root, dirs, files in os.walk(temp_dir, topdown=False):
                    for file in files:
                        try:
                            os.remove(os.path.join(root, file))
                        except Exception as e:
                            cleanup_errors.append(f"ç›®å½•æ–‡ä»¶ {file}: {e}")
                    for dir in dirs:
                        try:
                            os.rmdir(os.path.join(root, dir))
                        except Exception as e:
                            cleanup_errors.append(f"å­ç›®å½• {dir}: {e}")

                # åˆ é™¤ä¸»ç›®å½•
                os.rmdir(temp_dir)
                logger.debug(f"âœ… æ¸…ç†ä¸´æ—¶ç›®å½•: {temp_dir}")

            except Exception as e:
                cleanup_errors.append(f"ç›®å½• {temp_dir}: {e}")
                logger.warning(f"âš ï¸ æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {temp_dir} - {e}")

                # å¦‚æœå¸¸è§„åˆ é™¤å¤±è´¥ï¼Œå°è¯•å¼ºåˆ¶åˆ é™¤ï¼ˆä»…é™Windowsï¼‰
                if os.name == 'nt':
                    try:
                        shutil.rmtree(temp_dir, ignore_errors=True)
                        logger.info(f"ğŸ”§ å¼ºåˆ¶æ¸…ç†ä¸´æ—¶ç›®å½•: {temp_dir}")
                    except Exception as e2:
                        cleanup_errors.append(f"å¼ºåˆ¶åˆ é™¤ {temp_dir}: {e2}")

        # è®°å½•æ¸…ç†ç»“æœ
        if cleanup_errors:
            logger.warning(f"âš ï¸ éƒ¨åˆ†ä¸´æ—¶æ–‡ä»¶æ¸…ç†å¤±è´¥: {'; '.join(cleanup_errors)}")
        else:
            logger.debug("âœ… æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶æ¸…ç†å®Œæˆ")

    def set_progress_callback(self, callback, download_id: str = None):
        """è®¾ç½®è¿›åº¦å›è°ƒå‡½æ•°"""
        self._progress_callback = callback
        self._download_id = download_id
        logger.debug(f"âœ… PyTubeFixè®¾ç½®è¿›åº¦å›è°ƒ: {download_id}")

    def _download_with_progress(self, stream, output_path: str) -> str:
        """å¸¦è¿›åº¦ç›‘æ§çš„ä¸‹è½½æ–¹æ³•"""
        try:

            # è·å–æ–‡ä»¶å¤§å°
            file_size = getattr(stream, 'filesize', 0)
            if file_size == 0:
                # å¦‚æœæ— æ³•è·å–æ–‡ä»¶å¤§å°ï¼Œç›´æ¥ä¸‹è½½
                logger.debug("âš ï¸ æ— æ³•è·å–æ–‡ä»¶å¤§å°ï¼Œä½¿ç”¨æ™®é€šä¸‹è½½")
                return stream.download(output_path=output_path)

            # å¯åŠ¨è¿›åº¦ç›‘æ§çº¿ç¨‹
            progress_stop_event = threading.Event()

            # é¢„æµ‹ä¸‹è½½æ–‡ä»¶è·¯å¾„ï¼ˆPyTubeFixçš„é»˜è®¤å‘½åè§„åˆ™ï¼‰
            safe_title = self._sanitize_filename(stream.default_filename)
            predicted_file_path = os.path.join(output_path, safe_title)

            progress_thread = threading.Thread(
                target=self._monitor_download_progress,
                args=(predicted_file_path, file_size, progress_stop_event),
                daemon=True
            )
            progress_thread.start()

            try:
                # æ‰§è¡Œä¸‹è½½
                downloaded_file = stream.download(output_path=output_path)

                # åœæ­¢è¿›åº¦ç›‘æ§
                progress_stop_event.set()

                # ç­‰å¾…ç›‘æ§çº¿ç¨‹ç»“æŸï¼ˆæœ€å¤šç­‰å¾…2ç§’ï¼‰
                progress_thread.join(timeout=2.0)

                # å‘é€100%è¿›åº¦
                self._update_progress(file_size, file_size)

                return downloaded_file

            except Exception as e:
                # ç¡®ä¿åœæ­¢è¿›åº¦ç›‘æ§
                progress_stop_event.set()
                # ä¸ç­‰å¾…çº¿ç¨‹ç»“æŸï¼Œè®©å®ƒè‡ªç„¶é€€å‡º
                raise e

        except Exception as e:
            logger.error(f"âŒ PyTubeFixè¿›åº¦ä¸‹è½½å¤±è´¥: {e}")
            # é™çº§åˆ°æ™®é€šä¸‹è½½
            return stream.download(output_path=output_path)

    def _monitor_download_progress(self, file_path: str, total_size: int, stop_event: threading.Event):
        """ç›‘æ§ä¸‹è½½è¿›åº¦"""
        try:
            last_size = 0
            file_found = False
            wait_count = 0
            max_wait = 20  # æœ€å¤šç­‰å¾…10ç§’ï¼ˆ20 * 0.5ç§’ï¼‰

            while not stop_event.is_set():
                try:
                    if os.path.exists(file_path):
                        file_found = True
                        current_size = os.path.getsize(file_path)
                        if current_size != last_size:
                            self._update_progress(current_size, total_size)
                            last_size = current_size
                    else:
                        # æ–‡ä»¶è¿˜ä¸å­˜åœ¨ï¼Œå¯èƒ½ä¸‹è½½è¿˜æ²¡å¼€å§‹
                        if not file_found:
                            wait_count += 1
                            if wait_count > max_wait:
                                logger.debug("âš ï¸ ç­‰å¾…ä¸‹è½½æ–‡ä»¶åˆ›å»ºè¶…æ—¶ï¼Œåœæ­¢ç›‘æ§")
                                break
                        else:
                            # æ–‡ä»¶æ›¾ç»å­˜åœ¨ä½†ç°åœ¨ä¸å­˜åœ¨äº†ï¼Œå¯èƒ½è¢«ç§»åŠ¨æˆ–é‡å‘½å
                            logger.debug("âš ï¸ ä¸‹è½½æ–‡ä»¶æ¶ˆå¤±ï¼Œå¯èƒ½å·²å®Œæˆå¹¶è¢«é‡å‘½å")
                            break

                    # æ¯0.5ç§’æ£€æŸ¥ä¸€æ¬¡
                    time.sleep(0.5)

                except Exception as e:
                    logger.debug(f"âš ï¸ è¿›åº¦ç›‘æ§å¼‚å¸¸: {e}")
                    break

        except Exception as e:
            logger.debug(f"âš ï¸ è¿›åº¦ç›‘æ§çº¿ç¨‹å¼‚å¸¸: {e}")

    def _update_progress(self, current: int, total: int):
        """æ›´æ–°ä¸‹è½½è¿›åº¦"""
        if self._progress_callback:
            try:
                # ä½¿ç”¨ç»Ÿä¸€çš„è¿›åº¦å¤„ç†å·¥å…·
                from core.file_utils import ProgressUtils

                # æ ¼å¼åŒ–è¿›åº¦æ•°æ®
                progress_data = ProgressUtils.format_progress_data(
                    max(0, current), max(0, total), 'downloading'
                )

                # å®‰å…¨çš„è¿›åº¦å›è°ƒ
                ProgressUtils.safe_progress_callback(self._progress_callback, progress_data)

                progress = progress_data['progress_percent']
                logger.debug(f"ğŸ“Š PyTubeFixè¿›åº¦: {progress}% ({current}/{total})")
            except Exception as e:
                logger.debug(f"âš ï¸ PyTubeFixè¿›åº¦å›è°ƒå¤±è´¥: {e}")

    def get_info(self) -> Dict[str, Any]:
        """è·å–ä¸‹è½½å™¨ä¿¡æ¯ï¼ˆåŒ…å«ç¼“å­˜çŠ¶æ€ï¼‰"""
        status_info = self.po_token_manager.get_status_info()
        cache_info = self._get_cache_info()

        return {
            'name': self.name,
            'version': self.version,
            'proxy': self.proxy,
            'po_token_available': status_info['po_token_available'],
            'visitor_data_available': status_info['visitor_data_available'],
            'oauth2_available': status_info['oauth2_available'],
            'available': self.version != 'not_installed',
            'supports_youtube': True,
            'supports_other_sites': False,
            'technical_route': 'web_parsing',
            'supported_qualities': ['4k', '1440p', '1080p', '720p', '480p', '360p', '240p', '144p', 'audio', 'best', 'worst'],
            'cache_enabled': True,
            'cache_info': cache_info,
            'optimizations': ['youtube_object_caching', 'duplicate_extraction_prevention', '4k_adaptive_support']
        }
