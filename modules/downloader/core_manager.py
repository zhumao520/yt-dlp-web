# -*- coding: utf-8 -*-
"""
æ ¸å¿ƒä¸‹è½½ç®¡ç†å™¨ - ç²¾ç®€ç‰ˆ

ä¸“æ³¨äºæ ¸å¿ƒä¸‹è½½ç®¡ç†åŠŸèƒ½ï¼Œç§»é™¤å¤æ‚çš„è¾…åŠ©åŠŸèƒ½
"""

import os
import uuid
import logging
import threading
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional, List
from concurrent.futures import ThreadPoolExecutor

logger = logging.getLogger(__name__)


class CoreDownloadManager:
    """æ ¸å¿ƒä¸‹è½½ç®¡ç†å™¨ - ç²¾ç®€ç‰ˆ"""
    
    def __init__(self):
        self.downloads: Dict[str, Dict[str, Any]] = {}
        self.lock = threading.RLock()
        self.executor = None
        
        # å¯¼å…¥è¾…åŠ©æ¨¡å—
        self._import_helpers()
        self._initialize()
    
    def _import_helpers(self):
        """å¯¼å…¥è¾…åŠ©æ¨¡å—"""
        try:
            from .retry_manager import RetryManager
            from .ffmpeg_tools import FFmpegTools
            from .filename_processor import FilenameProcessor
            from .youtube_strategies import YouTubeStrategies
            from .video_extractor import VideoExtractor
            
            self.retry_manager = RetryManager()
            self.ffmpeg_tools = FFmpegTools()
            self.filename_processor = FilenameProcessor()
            self.youtube_strategies = YouTubeStrategies()
            self.video_extractor = VideoExtractor()
            
            logger.info("âœ… è¾…åŠ©æ¨¡å—å¯¼å…¥å®Œæˆ")
            
        except ImportError as e:
            logger.warning(f"âš ï¸ éƒ¨åˆ†è¾…åŠ©æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
            # åˆ›å»ºç©ºçš„å ä½ç¬¦
            self.retry_manager = None
            self.ffmpeg_tools = None
            self.filename_processor = None
            self.youtube_strategies = None
            self.video_extractor = None
    
    def _initialize(self):
        """åˆå§‹åŒ–ä¸‹è½½ç®¡ç†å™¨"""
        try:
            # çµæ´»çš„é…ç½®å¯¼å…¥
            try:
                from core.config import get_config
            except ImportError:
                try:
                    from app.core.config import get_config
                except ImportError:
                    def get_config(key, default=None):
                        logger.warning(f"âš ï¸ æ— æ³•å¯¼å…¥é…ç½®æ¨¡å—ï¼Œä½¿ç”¨é»˜è®¤å€¼: {key} = {default}")
                        return default

            # è·å–é…ç½®
            max_concurrent = get_config('downloader.max_concurrent', 3)
            self.output_dir = Path(get_config('downloader.output_dir', '/app/downloads'))
            self.temp_dir = Path(get_config('downloader.temp_dir', '/app/temp'))

            # åˆ›å»ºç›®å½•
            self.output_dir.mkdir(parents=True, exist_ok=True)
            self.temp_dir.mkdir(parents=True, exist_ok=True)

            # æ¸…ç†é—ç•™ä»»åŠ¡
            self._cleanup_orphaned_downloads()

            # åˆ›å»ºçº¿ç¨‹æ± 
            self.executor = ThreadPoolExecutor(max_workers=max_concurrent)

            # å¯åŠ¨è‡ªåŠ¨æ¸…ç†
            self._start_cleanup()

            logger.info(f"âœ… æ ¸å¿ƒä¸‹è½½ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ - æœ€å¤§å¹¶å‘: {max_concurrent}")

        except Exception as e:
            logger.error(f"âŒ æ ¸å¿ƒä¸‹è½½ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _cleanup_orphaned_downloads(self):
        """æ¸…ç†é—ç•™çš„ä¸‹è½½ä»»åŠ¡"""
        try:
            # çµæ´»çš„æ•°æ®åº“å¯¼å…¥
            try:
                from core.database import get_database
            except ImportError:
                try:
                    from app.core.database import get_database
                except ImportError:
                    logger.warning("âš ï¸ æ— æ³•å¯¼å…¥æ•°æ®åº“æ¨¡å—ï¼Œè·³è¿‡æ¸…ç†é—ç•™ä»»åŠ¡")
                    return
            
            db = get_database()
            orphaned_downloads = db.execute_query('''
                SELECT id, url FROM downloads
                WHERE status IN ('pending', 'downloading')
            ''')

            if orphaned_downloads:
                logger.info(f"ğŸ§¹ å‘ç° {len(orphaned_downloads)} ä¸ªé—ç•™ä¸‹è½½ä»»åŠ¡ï¼Œæ­£åœ¨æ¸…ç†...")
                
                for download in orphaned_downloads:
                    db.execute_update('''
                        UPDATE downloads
                        SET status = 'failed',
                            error_message = 'åº”ç”¨é‡å¯ï¼Œä»»åŠ¡å·²å–æ¶ˆ',
                            completed_at = CURRENT_TIMESTAMP
                        WHERE id = ?
                    ''', (download['id'],))
                
                logger.info(f"âœ… å·²æ¸…ç† {len(orphaned_downloads)} ä¸ªé—ç•™ä¸‹è½½ä»»åŠ¡")

        except Exception as e:
            logger.error(f"âŒ æ¸…ç†é—ç•™ä¸‹è½½ä»»åŠ¡å¤±è´¥: {e}")
    
    def _start_cleanup(self):
        """å¯åŠ¨è‡ªåŠ¨æ¸…ç†"""
        try:
            from .cleanup import get_cleanup_manager
            cleanup_manager = get_cleanup_manager()
            cleanup_manager.start()
        except Exception as e:
            logger.warning(f"âš ï¸ å¯åŠ¨è‡ªåŠ¨æ¸…ç†å¤±è´¥: {e}")
    
    def create_download(self, url: str, options: Dict[str, Any] = None) -> str:
        """åˆ›å»ºä¸‹è½½ä»»åŠ¡"""
        try:
            download_id = str(uuid.uuid4())
            
            # åˆ›å»ºä¸‹è½½è®°å½•
            download_info = {
                'id': download_id,
                'url': url,
                'status': 'pending',
                'progress': 0,
                'title': None,
                'file_path': None,
                'file_size': None,
                'error_message': None,
                'created_at': datetime.now(),
                'completed_at': None,
                'options': options or {},
                'retry_count': 0,
                'max_retries': self._get_max_retries(options)
            }
            
            with self.lock:
                self.downloads[download_id] = download_info
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            self._save_to_database(download_id, url)
            
            # å‘é€äº‹ä»¶
            self._emit_event('DOWNLOAD_STARTED', {
                'download_id': download_id,
                'url': url,
                'options': options
            })
            
            # æäº¤ä¸‹è½½ä»»åŠ¡
            self.executor.submit(self._execute_download, download_id)
            
            logger.info(f"ğŸ“¥ åˆ›å»ºä¸‹è½½ä»»åŠ¡: {download_id} - {url}")
            return download_id
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºä¸‹è½½ä»»åŠ¡å¤±è´¥: {e}")
            raise
    
    def get_download(self, download_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ä¸‹è½½ä¿¡æ¯"""
        with self.lock:
            return self.downloads.get(download_id)
    
    def get_all_downloads(self) -> List[Dict[str, Any]]:
        """è·å–æ‰€æœ‰ä¸‹è½½"""
        with self.lock:
            return list(self.downloads.values())
    
    def cancel_download(self, download_id: str) -> bool:
        """å–æ¶ˆä¸‹è½½"""
        try:
            with self.lock:
                download_info = self.downloads.get(download_id)
                if not download_info:
                    return False
                
                if download_info['status'] in ['completed', 'failed', 'cancelled']:
                    return False
                
                download_info['status'] = 'cancelled'
                download_info['error_message'] = 'ç”¨æˆ·å–æ¶ˆ'
            
            # æ›´æ–°æ•°æ®åº“
            self._update_database_status(download_id, 'cancelled', error_message='ç”¨æˆ·å–æ¶ˆ')
            
            logger.info(f"ğŸš« å–æ¶ˆä¸‹è½½: {download_id}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ å–æ¶ˆä¸‹è½½å¤±è´¥: {e}")
            return False
    
    def _execute_download(self, download_id: str):
        """æ‰§è¡Œä¸‹è½½ä»»åŠ¡"""
        try:
            with self.lock:
                download_info = self.downloads.get(download_id)
                if not download_info:
                    return

                url = download_info['url']
                options = download_info['options']

            logger.info(f"ğŸ”„ å¼€å§‹æ‰§è¡Œä¸‹è½½: {download_id} - {url}")

            # æ›´æ–°çŠ¶æ€ä¸ºä¸‹è½½ä¸­
            self._update_download_status(download_id, 'downloading', 0)

            # æå–è§†é¢‘ä¿¡æ¯
            if self.video_extractor:
                video_info = self.video_extractor.extract_info(url)
            else:
                video_info = self._fallback_extract_info(url)
            
            if not video_info:
                self._handle_download_failure(download_id, 'æ— æ³•è·å–è§†é¢‘ä¿¡æ¯')
                return

            # æ›´æ–°æ ‡é¢˜
            title = video_info.get('title', 'Unknown')
            with self.lock:
                self.downloads[download_id]['title'] = title

            # æ‰§è¡Œä¸‹è½½
            file_path = self._download_video(download_id, url, video_info, options)

            if file_path and Path(file_path).exists():
                logger.info(f"âœ… ä¸‹è½½å®Œæˆ: {download_id} - {title}")
            else:
                self._handle_download_failure(download_id, 'ä¸‹è½½æ–‡ä»¶ä¸å­˜åœ¨')

        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½æ‰§è¡Œå¤±è´¥ {download_id}: {e}")
            self._handle_download_failure(download_id, str(e))
    
    def _handle_download_failure(self, download_id: str, error_msg: str):
        """å¤„ç†ä¸‹è½½å¤±è´¥"""
        try:
            if self.retry_manager:
                # ä½¿ç”¨é‡è¯•ç®¡ç†å™¨
                should_retry = self.retry_manager.should_retry(download_id, error_msg)
                if should_retry:
                    self.retry_manager.schedule_retry(download_id, self._execute_download)
                    return
            
            # æ ‡è®°ä¸ºæœ€ç»ˆå¤±è´¥
            self._update_download_status(download_id, 'failed', error_message=error_msg)
            
            # å‘é€å¤±è´¥äº‹ä»¶
            self._emit_event('DOWNLOAD_FAILED', {
                'download_id': download_id,
                'error': error_msg
            })
            
            logger.error(f"âŒ ä¸‹è½½æœ€ç»ˆå¤±è´¥: {download_id} - {error_msg}")
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†ä¸‹è½½å¤±è´¥æ—¶å‡ºé”™: {e}")
    
    def _download_video(self, download_id: str, url: str, video_info: Dict[str, Any], options: Dict[str, Any]) -> Optional[str]:
        """ä¸‹è½½è§†é¢‘ - å§”æ‰˜ç»™ç­–ç•¥æ¨¡å—"""
        try:
            if self.youtube_strategies and self._is_youtube_url(url):
                logger.info(f"ğŸ¬ ä½¿ç”¨YouTubeä¸“ç”¨ç­–ç•¥ä¸‹è½½: {url}")
                return self.youtube_strategies.download(download_id, url, video_info, options)
            else:
                logger.info(f"ğŸŒ ä½¿ç”¨é€šç”¨yt-dlpä¸‹è½½éYouTubeç½‘ç«™: {url}")
                return self._fallback_download(download_id, url, video_info, options)
        except Exception as e:
            logger.error(f"âŒ è§†é¢‘ä¸‹è½½å¤±è´¥: {e}")
            return None

    def _is_youtube_url(self, url: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä¸ºYouTube URL"""
        try:
            from urllib.parse import urlparse
            parsed = urlparse(url.lower())

            # YouTube å®˜æ–¹åŸŸååˆ—è¡¨
            youtube_domains = [
                'youtube.com',
                'www.youtube.com',
                'm.youtube.com',
                'music.youtube.com',
                'youtu.be',
                'youtube-nocookie.com',
                'www.youtube-nocookie.com'
            ]

            is_youtube = parsed.netloc in youtube_domains

            if is_youtube:
                logger.debug(f"âœ… æ£€æµ‹åˆ°YouTube URL: {parsed.netloc}")
            else:
                logger.debug(f"ğŸŒ æ£€æµ‹åˆ°éYouTube URL: {parsed.netloc}")

            return is_youtube

        except Exception as e:
            logger.error(f"âŒ URLæ£€æµ‹å¤±è´¥: {e}")
            # å¦‚æœæ£€æµ‹å¤±è´¥ï¼Œä¿å®ˆåœ°å‡è®¾ä¸æ˜¯YouTube
            return False
    
    def _fallback_extract_info(self, url: str) -> Optional[Dict[str, Any]]:
        """å¤‡ç”¨ä¿¡æ¯æå– - é’ˆå¯¹ä¸åŒç½‘ç«™ä¼˜åŒ–"""
        try:
            import yt_dlp

            # æ„å»ºåŸºæœ¬é€‰é¡¹
            ydl_opts = {
                'quiet': True,
                'no_warnings': False,
                'extract_flat': False,
            }

            # ä½¿ç”¨æ–°çš„å¹³å°é…ç½®ç³»ç»Ÿ
            platform_config = self._get_platform_config(url, 'best')
            ydl_opts.update(platform_config)

            # æ·»åŠ ä»£ç†é…ç½®
            proxy = self._get_proxy_config()
            if proxy:
                ydl_opts['proxy'] = proxy
                logger.debug(f"âœ… ä¿¡æ¯æå–ä½¿ç”¨ä»£ç†: {proxy}")

            # æ·»åŠ  Cookies æ”¯æŒ
            cookies_path = self._get_cookies_for_site(url)
            if cookies_path:
                ydl_opts['cookiefile'] = cookies_path
                logger.debug(f"âœ… ä¿¡æ¯æå–ä½¿ç”¨Cookies: {cookies_path}")

            logger.info(f"ğŸ” ä¿¡æ¯æå–é…ç½®: {self._get_site_name(url)}")

            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                info = ydl.extract_info(url, download=False)
                if info:
                    logger.info(f"âœ… ä¿¡æ¯æå–æˆåŠŸ: {info.get('title', 'Unknown')}")
                    return info
                else:
                    logger.warning("âš ï¸ ä¿¡æ¯æå–è¿”å›ç©ºç»“æœ")
                    return None

        except Exception as e:
            logger.error(f"âŒ å¤‡ç”¨ä¿¡æ¯æå–å¤±è´¥: {e}")
            return None
    
    def _fallback_download(self, download_id: str, url: str, video_info: Dict[str, Any], options: Dict[str, Any]) -> Optional[str]:
        """å¤‡ç”¨ä¸‹è½½æ–¹æ³• - é’ˆå¯¹ä¸åŒç½‘ç«™ä¼˜åŒ–ï¼ŒåŒ…å«FFmpegè‡ªåŠ¨åˆå¹¶"""
        try:
            import yt_dlp

            # æ„å»ºåŸºæœ¬é€‰é¡¹
            ydl_opts = {
                'outtmpl': str(self.output_dir / f'{download_id}.%(ext)s'),
                'retries': 3,
                'fragment_retries': 3,
                'extractor_retries': 3,
                'no_warnings': False,
                'ignoreerrors': False,
            }

            # æ·»åŠ FFmpegé…ç½®ï¼Œç¡®ä¿è‡ªåŠ¨åˆå¹¶
            ffmpeg_path = self._get_ffmpeg_path()
            if ffmpeg_path:
                ydl_opts['ffmpeg_location'] = ffmpeg_path
                ydl_opts['merge_output_format'] = 'mp4'  # å¼ºåˆ¶åˆå¹¶ä¸ºMP4æ ¼å¼
                logger.info(f"âœ… é…ç½®FFmpegè‡ªåŠ¨åˆå¹¶: {ffmpeg_path}")
            else:
                logger.warning("âš ï¸ æœªæ‰¾åˆ°FFmpegï¼Œè§†é¢‘å¯èƒ½æ— æ³•è‡ªåŠ¨åˆå¹¶")

            # ä½¿ç”¨æ–°çš„å¹³å°é…ç½®ç³»ç»Ÿï¼ˆåŒ…å«æ ¼å¼é€‰æ‹©ï¼‰
            platform_config = self._get_platform_config(url, options.get('quality', 'best'))
            ydl_opts.update(platform_config)

            # æ·»åŠ ä»£ç†é…ç½®
            proxy = self._get_proxy_config()
            if proxy:
                ydl_opts['proxy'] = proxy
                logger.info(f"âœ… å¤‡ç”¨ä¸‹è½½ä½¿ç”¨ä»£ç†: {proxy}")

            # æ·»åŠ  Cookies æ”¯æŒ
            cookies_path = self._get_cookies_for_site(url)
            if cookies_path:
                ydl_opts['cookiefile'] = cookies_path
                logger.info(f"âœ… å¤‡ç”¨ä¸‹è½½ä½¿ç”¨Cookies: {cookies_path}")

            logger.info(f"ğŸŒ å¤‡ç”¨ä¸‹è½½é…ç½®: {self._get_site_name(url)}")

            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                ydl.download([url])

            # æŸ¥æ‰¾ä¸‹è½½çš„æ–‡ä»¶
            for file_path in self.output_dir.glob(f'{download_id}.*'):
                if file_path.is_file():
                    logger.info(f"âœ… å¤‡ç”¨ä¸‹è½½æˆåŠŸ: {file_path}")
                    return str(file_path)

            logger.warning("âš ï¸ å¤‡ç”¨ä¸‹è½½å®Œæˆä½†æœªæ‰¾åˆ°æ–‡ä»¶")
            return None

        except Exception as e:
            logger.error(f"âŒ å¤‡ç”¨ä¸‹è½½å¤±è´¥: {e}")
            return None

    def _get_platform_config(self, url: str, quality: str = 'best') -> Dict[str, Any]:
        """ä½¿ç”¨æ–°çš„å¹³å°é…ç½®ç³»ç»Ÿ"""
        try:
            from .platforms import get_platform_for_url

            # è·å–å¯¹åº”çš„å¹³å°å¤„ç†å™¨
            platform = get_platform_for_url(url)

            # è·å–å¹³å°ç‰¹å®šé…ç½®
            config = platform.get_config(url, quality)

            logger.info(f"ğŸ¯ ä½¿ç”¨å¹³å°é…ç½®: {platform.name} for {url}")
            return config

        except Exception as e:
            logger.error(f"âŒ è·å–å¹³å°é…ç½®å¤±è´¥: {e}")
            # å›é€€åˆ°æ—§çš„é…ç½®æ–¹æ³•
            return self._get_site_specific_config(url)

    def _get_site_specific_config(self, url: str) -> Dict[str, Any]:
        """è·å–ç½‘ç«™ç‰¹å®šé…ç½®"""
        try:
            from urllib.parse import urlparse
            parsed = urlparse(url.lower())
            domain = parsed.netloc

            # X å¹³å°ï¼ˆTwitterï¼‰ç‰¹æ®Šé…ç½® - å¢å¼ºç‰ˆ
            if any(x in domain for x in ['twitter.com', 'x.com']):
                return {
                    'http_headers': {
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                        'Accept-Language': 'en-US,en;q=0.5',
                        'Accept-Encoding': 'gzip, deflate',
                        'DNT': '1',
                        'Connection': 'keep-alive',
                        'Upgrade-Insecure-Requests': '1',
                        'Referer': 'https://twitter.com/',
                        'Origin': 'https://twitter.com',
                    },
                    'sleep_interval': 2,  # å¢åŠ å»¶è¿Ÿé¿å…é™åˆ¶
                    'max_sleep_interval': 5,
                    'writesubtitles': False,
                    'writeautomaticsub': False,
                    'writethumbnail': True,  # ä¿ç•™ç¼©ç•¥å›¾
                    # æ›´å®½æ¾çš„æ ¼å¼é€‰æ‹©ç­–ç•¥
                    'format': 'best[ext=mp4]/best[ext=m4v]/best[height<=1080]/best[height<=720]/best[height<=480]/best/worst',
                    # å¢å¼ºçš„ X å¹³å°é€‰é¡¹
                    'extractor_args': {
                        'twitter': {
                            'api': ['syndication', 'legacy', 'graphql'],  # ä½¿ç”¨æ‰€æœ‰å¯ç”¨ API
                            'legacy_api': True,
                            'guest_token': True,
                            'syndication_api': True,
                        }
                    },
                    # ç½‘ç»œä¼˜åŒ–
                    'socket_timeout': 60,
                    'fragment_retries': 8,
                    'http_chunk_size': 10485760,  # 10MB chunks
                    # å¢å¼ºé‡è¯•ç­–ç•¥
                    'retries': 8,
                    'extractor_retries': 5,
                    # é”™è¯¯å¤„ç†
                    'ignoreerrors': False,
                    'no_warnings': False,
                    # åœ°åŒºç»•è¿‡
                    'geo_bypass': True,
                    'geo_bypass_country': 'US',
                    # è®¤è¯è®¾ç½®
                    'username': None,
                    'password': None,
                    'netrc': False,
                }

            # Instagram ç‰¹æ®Šé…ç½®
            elif 'instagram.com' in domain:
                return {
                    'http_headers': {
                        'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1',
                        'Accept': '*/*',
                        'Accept-Language': 'en-US,en;q=0.9',
                    },
                    'sleep_interval': 2,
                    'max_sleep_interval': 5,
                    'format': 'best[height<=1080]/best',
                }

            # TikTok ç‰¹æ®Šé…ç½®
            elif 'tiktok.com' in domain:
                return {
                    'http_headers': {
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                        'Referer': 'https://www.tiktok.com/',
                        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                        'Accept-Language': 'en-US,en;q=0.9',
                        'Accept-Encoding': 'gzip, deflate, br',
                        'Sec-Fetch-Dest': 'document',
                        'Sec-Fetch-Mode': 'navigate',
                        'Sec-Fetch-Site': 'none',
                        'Sec-Fetch-User': '?1',
                    },
                    'sleep_interval': 1,
                    'max_sleep_interval': 3,
                    # TikTok ä¸“ç”¨æ ¼å¼é€‰æ‹©
                    'format': 'best[ext=mp4][height<=1080]/best[ext=webm][height<=1080]/best[height<=1080]/best/worst',
                    # TikTok ç‰¹æ®Šé€‰é¡¹
                    'extractor_args': {
                        'tiktok': {
                            'api': ['web', 'mobile'],  # ä½¿ç”¨å¤šç§ API
                        }
                    },
                    # å¢åŠ é‡è¯•å’Œå®¹é”™
                    'retries': 4,
                    'fragment_retries': 4,
                    'extractor_retries': 3,
                    'writesubtitles': False,  # TikTok é€šå¸¸æ²¡æœ‰å­—å¹•
                    'writeautomaticsub': False,
                }

            # Bilibili ç‰¹æ®Šé…ç½®
            elif 'bilibili.com' in domain:
                return {
                    'http_headers': {
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                        'Referer': 'https://www.bilibili.com/',
                        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                        'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
                        'Accept-Encoding': 'gzip, deflate, br',
                        'Origin': 'https://www.bilibili.com',
                    },
                    'sleep_interval': 1,
                    'max_sleep_interval': 2,
                    # Bilibili ä¸“ç”¨æ ¼å¼é€‰æ‹©
                    'format': 'best[ext=mp4][height<=1080]/best[ext=flv][height<=1080]/best[height<=1080]/best/worst',
                    # Bilibili ç‰¹æ®Šé€‰é¡¹
                    'extractor_args': {
                        'bilibili': {
                            'api': ['web', 'app'],  # ä½¿ç”¨å¤šç§ API
                        }
                    },
                    # å¢åŠ é‡è¯•å’Œå®¹é”™
                    'retries': 4,
                    'fragment_retries': 4,
                    'extractor_retries': 3,
                    'writesubtitles': True,   # Bilibili æ”¯æŒå­—å¹•
                    'writeautomaticsub': True,
                    'subtitleslangs': ['zh-CN', 'zh-TW', 'en'],  # æ”¯æŒå¤šè¯­è¨€å­—å¹•
                }

            # é»˜è®¤é…ç½®
            else:
                return {
                    'http_headers': {
                        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                    },
                    'sleep_interval': 1,
                    'max_sleep_interval': 2,
                }

        except Exception as e:
            logger.error(f"âŒ è·å–ç½‘ç«™é…ç½®å¤±è´¥: {e}")
            return {}



    def _get_max_retries(self, options: Dict[str, Any] = None) -> int:
        """è·å–æœ€å¤§é‡è¯•æ¬¡æ•°"""
        if options and 'max_retries' in options:
            return max(0, int(options['max_retries']))
        return 3  # é»˜è®¤å€¼

    def _get_ffmpeg_path(self) -> str:
        """è·å–FFmpegè·¯å¾„ - ä½¿ç”¨æ™ºèƒ½é…ç½®ç®¡ç†å™¨"""
        try:
            from .ffmpeg_config import get_ffmpeg_path_for_ytdlp
            ffmpeg_path = get_ffmpeg_path_for_ytdlp()
            if ffmpeg_path:
                logger.debug(f"âœ… æ™ºèƒ½æ£€æµ‹FFmpegè·¯å¾„: {ffmpeg_path}")
                return ffmpeg_path
            else:
                logger.warning("âš ï¸ æ™ºèƒ½æ£€æµ‹æœªæ‰¾åˆ°FFmpegè·¯å¾„")
                return None

        except Exception as e:
            logger.debug(f"ğŸ” æ™ºèƒ½FFmpegè·¯å¾„æ£€æµ‹å¤±è´¥: {e}")
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä¼ ç»Ÿæ£€æµ‹
            return self._get_ffmpeg_path_fallback()

    def _get_ffmpeg_path_fallback(self) -> str:
        """FFmpegè·¯å¾„æ£€æµ‹å¤‡ç”¨æ–¹æ¡ˆ"""
        try:
            # å°è¯•é¡¹ç›®è·¯å¾„
            from pathlib import Path
            project_ffmpeg = Path('ffmpeg/bin')
            if project_ffmpeg.exists():
                return str(project_ffmpeg.resolve())

            # å°è¯•ç³»ç»Ÿè·¯å¾„
            import shutil
            which_ffmpeg = shutil.which('ffmpeg')
            if which_ffmpeg:
                return str(Path(which_ffmpeg).parent)

            return None

        except Exception as e:
            logger.debug(f"ğŸ” å¤‡ç”¨FFmpegè·¯å¾„æ£€æµ‹å¤±è´¥: {e}")
            return None

    def _get_site_name(self, url: str) -> str:
        """è·å–ç½‘ç«™åç§°"""
        try:
            from urllib.parse import urlparse
            parsed = urlparse(url.lower())
            domain = parsed.netloc

            site_names = {
                'twitter.com': 'Twitter/X',
                'x.com': 'Twitter/X',
                'instagram.com': 'Instagram',
                'tiktok.com': 'TikTok',
                'bilibili.com': 'Bilibili',
                'youtube.com': 'YouTube',
                'youtu.be': 'YouTube',
                'facebook.com': 'Facebook',
                'vimeo.com': 'Vimeo',
                'dailymotion.com': 'Dailymotion'
            }

            for site_domain, site_name in site_names.items():
                if site_domain in domain:
                    return site_name

            return domain

        except Exception:
            return "æœªçŸ¥ç½‘ç«™"

    def _get_cookies_for_site(self, url: str) -> Optional[str]:
        """è·å–ç½‘ç«™å¯¹åº”çš„ Cookies æ–‡ä»¶"""
        try:
            # å°è¯•å¯¼å…¥ cookies ç®¡ç†å™¨
            from modules.cookies.manager import CookiesManager
            cookies_manager = CookiesManager()
            return cookies_manager.get_cookies_for_ytdlp(url)
        except Exception as e:
            logger.debug(f"ğŸ” è·å–Cookieså¤±è´¥: {e}")
            return None

    def _get_proxy_config(self) -> Optional[str]:
        """è·å–ä»£ç†é…ç½® - å¢å¼ºç‰ˆï¼Œæ”¯æŒä»£ç†å¥åº·æ£€æŸ¥"""
        try:
            # é¦–å…ˆå°è¯•ä»æ•°æ®åº“è·å–ä»£ç†é…ç½®
            from core.database import get_database
            db = get_database()
            proxy_config = db.get_proxy_config()

            if proxy_config and proxy_config.get('enabled'):
                # ä½¿ç”¨ç»Ÿä¸€çš„ä»£ç†è½¬æ¢å·¥å…·
                from core.proxy_converter import ProxyConverter
                proxy_url = ProxyConverter.build_proxy_url(proxy_config)

                # æµ‹è¯•ä»£ç†è¿æ¥
                test_result = ProxyConverter.test_proxy_connection(proxy_config, timeout=3)
                if test_result['success']:
                    logger.info(f"âœ… ä½¿ç”¨æ•°æ®åº“ä»£ç†é…ç½®: {proxy_config.get('proxy_type')}://{proxy_config.get('host')}:{proxy_config.get('port')}")
                    return proxy_url
                else:
                    logger.warning(f"âš ï¸ ä»£ç†è¿æ¥å¤±è´¥ï¼Œè·³è¿‡ä»£ç†: {proxy_config.get('host')}:{proxy_config.get('port')} - {test_result['message']}")
                    return None

            # å…¶æ¬¡å°è¯•ä»é…ç½®æ–‡ä»¶è·å–
            from core.config import get_config
            config = get_config()
            proxy_config = config.get('proxy', {})

            if proxy_config.get('enabled', False):
                proxy_type = proxy_config.get('type', 'http')
                proxy_host = proxy_config.get('host', '')
                proxy_port = proxy_config.get('port', '')

                if proxy_host and proxy_port:
                    proxy_url = f"{proxy_type}://{proxy_host}:{proxy_port}"
                    if self._test_proxy_connection(proxy_url):
                        logger.info(f"âœ… ä½¿ç”¨é…ç½®æ–‡ä»¶ä»£ç†: {proxy_url}")
                        return proxy_url
                    else:
                        logger.warning(f"âš ï¸ é…ç½®æ–‡ä»¶ä»£ç†è¿æ¥å¤±è´¥ï¼Œè·³è¿‡ä»£ç†: {proxy_host}:{proxy_port}")

            return None
        except Exception as e:
            logger.debug(f"ğŸ” è·å–ä»£ç†é…ç½®å¤±è´¥: {e}")
            return None



    def _save_to_database(self, download_id: str, url: str):
        """ä¿å­˜åˆ°æ•°æ®åº“"""
        try:
            from core.database import get_database
            db = get_database()
            db.save_download_record(download_id, url)
        except Exception as e:
            logger.warning(f"âš ï¸ ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥: {e}")

    def _update_database_status(self, download_id: str, status: str, **kwargs):
        """æ›´æ–°æ•°æ®åº“çŠ¶æ€"""
        try:
            from core.database import get_database
            db = get_database()
            db.update_download_status(download_id, status, **kwargs)
        except Exception as e:
            logger.warning(f"âš ï¸ æ›´æ–°æ•°æ®åº“çŠ¶æ€å¤±è´¥: {e}")

    def _emit_event(self, event_name: str, data: Dict[str, Any]):
        """å‘é€äº‹ä»¶"""
        try:
            from core.events import emit, Events
            event = getattr(Events, event_name, None)
            if event:
                emit(event, data)
        except Exception as e:
            logger.debug(f"ğŸ” å‘é€äº‹ä»¶å¤±è´¥: {e}")

    def _update_download_status(self, download_id: str, status: str, progress: int = None, **kwargs):
        """æ›´æ–°ä¸‹è½½çŠ¶æ€"""
        try:
            with self.lock:
                if download_id in self.downloads:
                    self.downloads[download_id]['status'] = status
                    if progress is not None:
                        self.downloads[download_id]['progress'] = progress
                    for key, value in kwargs.items():
                        self.downloads[download_id][key] = value

            # æ›´æ–°æ•°æ®åº“
            self._update_database_status(download_id, status, **kwargs)

            # å‘é€çŠ¶æ€å˜æ›´äº‹ä»¶
            if status == 'completed':
                # å‘é€ä¸‹è½½å®Œæˆäº‹ä»¶
                with self.lock:
                    download_info = self.downloads.get(download_id, {})

                self._emit_event('DOWNLOAD_COMPLETED', {
                    'download_id': download_id,
                    'file_path': kwargs.get('file_path'),
                    'title': download_info.get('title', 'Unknown'),
                    'file_size': kwargs.get('file_size')
                })
                logger.info(f"ğŸ“¡ å‘é€ä¸‹è½½å®Œæˆäº‹ä»¶: {download_id}")
            elif status in ['downloading', 'retrying']:
                # å‘é€è¿›åº¦äº‹ä»¶
                self._emit_event('DOWNLOAD_PROGRESS', {
                    'download_id': download_id,
                    'status': status,
                    'progress': progress or 0
                })

        except Exception as e:
            logger.error(f"âŒ æ›´æ–°ä¸‹è½½çŠ¶æ€å¤±è´¥: {e}")

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            if self.executor:
                self.executor.shutdown(wait=True)
            logger.info("âœ… æ ¸å¿ƒä¸‹è½½ç®¡ç†å™¨æ¸…ç†å®Œæˆ")
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†å¤±è´¥: {e}")


# å…¨å±€å®ä¾‹
_core_manager = None


def get_core_download_manager() -> CoreDownloadManager:
    """è·å–æ ¸å¿ƒä¸‹è½½ç®¡ç†å™¨å®ä¾‹"""
    global _core_manager
    if _core_manager is None:
        _core_manager = CoreDownloadManager()
    return _core_manager
